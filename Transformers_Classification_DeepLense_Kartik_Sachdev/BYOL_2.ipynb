{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUduHdRzRl3b"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kXHfhmj5Sg8I"
      },
      "outputs": [],
      "source": [
        "# %%bash\n",
        "# set -m\n",
        "# git clone https://github.com/sachdevkartik/DeepLense.git\n",
        "# cd DeepLense && git checkout kartik_contribution\n",
        "# cd ..\n",
        "# mv DeepLense/Transformers_Classification_DeepLense_Kartik_Sachdev/* .\n",
        "# rm -rf DeepLense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GO-o2tDFTzRi"
      },
      "outputs": [],
      "source": [
        "# %%bash\n",
        "# pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c1HY0pEaLFG",
        "outputId": "faafc9b6-dc46-4152-9980-5117273aec44"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5bBZlqLTw7f"
      },
      "outputs": [],
      "source": [
        "# %%bash\n",
        "# pip3 install --upgrade -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4PjBZQfY5oH"
      },
      "outputs": [],
      "source": [
        "# !pip uninstall numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBA_SAO_Y6rq"
      },
      "outputs": [],
      "source": [
        "# !pip install numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FLbLTB7NT-Iq"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import os\n",
        "import time\n",
        "import copy\n",
        "import json\n",
        "import yaml\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchinfo import summary\n",
        "import torchvision\n",
        "from typing import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RtAGUsIfUCxM"
      },
      "outputs": [],
      "source": [
        "from utils.util import *\n",
        "from config.data_config import DATASET\n",
        "from utils.dataset import DefaultDatasetSetupSSL\n",
        "from self_supervised.losses.contrastive_loss import (\n",
        "    ContrastiveLossEuclidean,\n",
        "    ContrastiveLossEmbedding,\n",
        "    SimCLR_Loss,\n",
        "    NegativeCosineSimilarity,\n",
        ")\n",
        "from self_supervised.losses.sym_neg_cos_sim_loss import SymNegCosineSimilarityLoss\n",
        "\n",
        "from models.modules.head import BYOLProjectionHead, BYOLPredictionHead\n",
        "from utils.scheduler import cosine_schedule\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from einops.layers.torch import Rearrange\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Rd3Ra8x_XG5D"
      },
      "outputs": [],
      "source": [
        "args = {\n",
        "    \"dataset_name\": \"Model_II\",\n",
        "    \"save\": \"data\",\n",
        "    \"num_workers\": 8,\n",
        "    \"train_config_path\": \"self_supervised/config/resnet_byol.yaml\",\n",
        "    \"cuda\": True,\n",
        "    \"log_dir\": \"logger\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "e_BlwV27XHye"
      },
      "outputs": [],
      "source": [
        "batch_size = 512\n",
        "\n",
        "dataset_name = args[\"dataset_name\"]\n",
        "dataset_dir = args[\"save\"]\n",
        "use_cuda = args[\"cuda\"]\n",
        "num_workers = args[\"num_workers\"]\n",
        "train_config_path = args[\"train_config_path\"]\n",
        "log_dir_base = args[\"log_dir\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "r3neGI8FXH6S"
      },
      "outputs": [],
      "source": [
        "classes = DATASET[f\"{dataset_name}\"][\"classes\"]\n",
        "num_classes = len(classes)\n",
        "\n",
        "# Open the YAML file and load its contents\n",
        "with open(train_config_path, \"r\") as file:\n",
        "    train_config = yaml.safe_load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Fk2BrahLXIQg"
      },
      "outputs": [],
      "source": [
        "epochs_pretrained = train_config[\"pretrained\"][\"num_epochs\"]\n",
        "epochs_finetuned = train_config[\"finetuned\"][\"num_epochs\"]\n",
        "\n",
        "learning_rate = train_config[\"optimizer_config\"][\"lr\"]\n",
        "margin = train_config[\"ssl\"][\"margin\"]\n",
        "num_channels = train_config[\"channels\"]\n",
        "temperature = train_config[\"ssl\"][\"temperature\"]\n",
        "network_type = train_config[\"network_type\"]\n",
        "image_size = train_config[\"image_size\"]\n",
        "optimizer_config = train_config[\"optimizer_config\"]\n",
        "\n",
        "backbone = train_config[\"backbone\"]\n",
        "\n",
        "make_directories([dataset_dir])\n",
        "seed_everything(seed=42)\n",
        "\n",
        "# logging\n",
        "current_time = time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime())\n",
        "log_dir = f\"{log_dir_base}/{current_time}\"\n",
        "init_logging_handler(log_dir_base, current_time)\n",
        "\n",
        "# dump config in logger\n",
        "with open(f\"{log_dir}/config.json\", \"w\") as fp:\n",
        "    json.dump(train_config, fp)\n",
        "\n",
        "# saving model path location\n",
        "model_path_pretrained = os.path.join(\n",
        "    f\"{log_dir}/checkpoint\",\n",
        "    f\"{network_type}_pretrained_{dataset_name}_{current_time}.pt\",\n",
        ")\n",
        "\n",
        "model_path_finetune = os.path.join(\n",
        "    f\"{log_dir}/checkpoint\",\n",
        "    f\"{network_type}_finetune_{dataset_name}_{current_time}.pt\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjU0UUKVXIiA",
        "outputId": "9abb6f3f-bc71-4bf3-8426-1e0fb0db15fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> Multiple Transforms\n",
            ">>> Multiple Transforms\n"
          ]
        }
      ],
      "source": [
        "# setup default dataset\n",
        "default_dataset_setup = DefaultDatasetSetupSSL(dir=None)\n",
        "default_dataset_setup.setup(dataset_name=dataset_name)\n",
        "default_dataset_setup.setup_transforms(image_size=image_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zLBymamXIx5",
        "outputId": "55e7933c-730f-4f97-c206-3905378761b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model_II dataset already exists\n",
            "train data: 89104\n"
          ]
        }
      ],
      "source": [
        "# trainset\n",
        "train_dataset = default_dataset_setup.get_dataset(mode=\"train\")\n",
        "# default_dataset_setup.visualize_dataset(train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxquTvHKUEN_",
        "outputId": "57116f52-9433-4ba5-dddb-e24585bacdeb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num of classes:  3\n",
            "torch.Size([512, 1, 224, 224])\n"
          ]
        }
      ],
      "source": [
        "# split in train and valid set\n",
        "split_ratio = 0.25  # 0.25\n",
        "valid_len = int(split_ratio * len(train_dataset))\n",
        "train_len = len(train_dataset) - valid_len\n",
        "\n",
        "train_dataset, val_set = random_split(train_dataset, [train_len, valid_len])\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=num_workers,\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    dataset=val_set, batch_size=batch_size, shuffle=True, num_workers=num_workers\n",
        ")\n",
        "\n",
        "# Load test dataset\n",
        "# testset = default_dataset_setup.get_dataset(mode=\"val\")\n",
        "# test_loader = DataLoader(dataset=testset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# size check\n",
        "sample = next(iter(train_loader))\n",
        "print(\"num of classes: \", num_classes)\n",
        "print(sample[0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "class BYOL2(nn.Module):\n",
        "    def __init__(self, backbone, num_ftrs=512):\n",
        "        super().__init__()\n",
        "\n",
        "        self.backbone = backbone\n",
        "        self.backbone[0] = nn.Conv2d(\n",
        "            1, 64, kernel_size=7, stride=2, padding=3, bias=False\n",
        "        )\n",
        "\n",
        "        self.projection_head = BYOLProjectionHead(num_ftrs, 1024, 256)\n",
        "        self.prediction_head = BYOLPredictionHead(256, 1024, 256)\n",
        "\n",
        "        self.backbone_momentum = copy.deepcopy(self.backbone)\n",
        "        self.projection_head_momentum = copy.deepcopy(self.projection_head)\n",
        "\n",
        "        deactivate_requires_grad(self.backbone_momentum)\n",
        "        deactivate_requires_grad(self.projection_head_momentum)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.backbone(x).flatten(start_dim=1)\n",
        "        z = self.projection_head(y)\n",
        "        p = self.prediction_head(z)\n",
        "        return p\n",
        "\n",
        "    def forward_momentum(self, x):\n",
        "        y = self.backbone_momentum(x).flatten(start_dim=1)\n",
        "        z = self.projection_head_momentum(y)\n",
        "        z = z.detach()\n",
        "        return z\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUdzIhd3YZyQ",
        "outputId": "60a4dd4d-1152-4f4a-ba9f-e332eacfc8b2"
      },
      "outputs": [],
      "source": [
        "# Create pretrain model\n",
        "resnet = torchvision.models.resnet34()\n",
        "backbone = nn.Sequential(*list(resnet.children())[:-1])\n",
        "\n",
        "num_ftrs_dict = {\n",
        "    \"resnet18\": 512,\n",
        "    \"resnet34\": 512,\n",
        "    \"resnet50\": 2048,\n",
        "\n",
        "}\n",
        "model = BYOL2(backbone, num_ftrs=num_ftrs_dict[\"resnet34\"])\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# model.to(device)\n",
        "\n",
        "# summary(model, input_size=(1, 1, 224, 224), device=\"cuda\")\n",
        "\n",
        "########################## Pretraining #############################\n",
        "\n",
        "# optimizer and loss function for pretrain\n",
        "optimizer_pretrain = torch.optim.SGD(model.parameters(), lr=0.06)\n",
        "\n",
        "# criterion\n",
        "criterion = NegativeCosineSimilarity()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Starting Training\")\n",
        "for epoch in range(epochs_pretrained):\n",
        "    total_loss = 0\n",
        "    best_loss = float(\"inf\")\n",
        "\n",
        "    momentum_val = cosine_schedule(epoch, epochs_pretrained, 0.996, 1)\n",
        "    for batch_idx, (x0, x1, label) in enumerate(train_loader):\n",
        "        update_momentum(model.backbone, model.backbone_momentum, m=momentum_val)\n",
        "        update_momentum(\n",
        "            model.projection_head, model.projection_head_momentum, m=momentum_val\n",
        "        )\n",
        "        x0 = x0.to(device)\n",
        "        x1 = x1.to(device)\n",
        "        p0 = model(x0)\n",
        "        z0 = model.forward_momentum(x0)\n",
        "        p1 = model(x1)\n",
        "        z1 = model.forward_momentum(x1)\n",
        "        loss = 0.5 * (criterion(p0, z1) + criterion(p1, z0))\n",
        "        total_loss += loss.detach()\n",
        "        loss.backward()\n",
        "        optimizer_pretrain.step()\n",
        "        optimizer_pretrain.zero_grad()\n",
        "        if batch_idx % 10 == 0:\n",
        "            print(\n",
        "                f\"Epoch [{epoch}/{epochs_pretrained}], Batch [{batch_idx}/{len(train_loader)}], Loss: {loss.item()}\"\n",
        "            )\n",
        "\n",
        "    if total_loss < best_loss:\n",
        "        best_loss = total_loss\n",
        "        best_model = copy.deepcopy(model)\n",
        "        torch.save(best_model.state_dict(), model_path_pretrained)\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"epoch: {epoch:>02}, loss: {avg_loss:.5f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYXa8R2bb_vD"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BYOL2(\n",
            "  (backbone): Sequential(\n",
            "    (0): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (4): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (2): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (5): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (2): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (3): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (6): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (2): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (3): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (4): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (5): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (7): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (2): BasicBlock(\n",
            "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  )\n",
            "  (projection_head): BYOLProjectionHead(\n",
            "    (layers): Sequential(\n",
            "      (0): Linear(in_features=512, out_features=1024, bias=False)\n",
            "      (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "      (3): Linear(in_features=1024, out_features=256, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (prediction_head): BYOLPredictionHead(\n",
            "    (layers): Sequential(\n",
            "      (0): Linear(in_features=256, out_features=1024, bias=False)\n",
            "      (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "      (3): Linear(in_features=1024, out_features=256, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (backbone_momentum): Sequential(\n",
            "    (0): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (4): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (2): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (5): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (2): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (3): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (6): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (2): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (3): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (4): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (5): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (7): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (2): BasicBlock(\n",
            "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  )\n",
            "  (projection_head_momentum): BYOLProjectionHead(\n",
            "    (layers): Sequential(\n",
            "      (0): Linear(in_features=512, out_features=1024, bias=False)\n",
            "      (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "      (3): Linear(in_features=1024, out_features=256, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# load model\n",
        "pretrained_path = \"logger/colab/CrossFormer_pretrained_Model_II_2023-07-31-23-14-06.pt\"\n",
        "model.load_state_dict(torch.load(pretrained_path))\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# model.backbone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FinetuneClassifier(nn.Module):\n",
        "    def __init__(self, backbone, head):\n",
        "        super(FinetuneClassifier, self).__init__()\n",
        "\n",
        "        deactivate_requires_grad(backbone)\n",
        "        self.backbone = backbone\n",
        "        self.pool = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
        "        self.rearrange = Rearrange(\"... () () -> ...\")\n",
        "        self.head = head\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.backbone(x)\n",
        "        z = self.pool(z)\n",
        "        z = self.rearrange(z)\n",
        "        z = self.head(z)\n",
        "        return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "classification_head = nn.Sequential(\n",
        "    nn.Linear(num_ftrs_dict[\"resnet34\"], 512),\n",
        "    nn.ReLU(),\n",
        "    nn.BatchNorm1d(512),\n",
        "    nn.Linear(512, num_classes),)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "===============================================================================================\n",
              "Layer (type:depth-idx)                        Output Shape              Param #\n",
              "===============================================================================================\n",
              "FinetuneClassifier                            --                        --\n",
              "├─Sequential: 1-1                             [1, 512, 7, 7]            --\n",
              "│    └─Conv2d: 2-1                            [1, 64, 112, 112]         (3,136)\n",
              "│    └─BatchNorm2d: 2-2                       [1, 64, 112, 112]         (128)\n",
              "│    └─ReLU: 2-3                              [1, 64, 112, 112]         --\n",
              "│    └─MaxPool2d: 2-4                         [1, 64, 56, 56]           --\n",
              "│    └─Sequential: 2-5                        [1, 64, 56, 56]           --\n",
              "│    │    └─BasicBlock: 3-1                   [1, 64, 56, 56]           (73,984)\n",
              "│    │    └─BasicBlock: 3-2                   [1, 64, 56, 56]           (73,984)\n",
              "│    │    └─BasicBlock: 3-3                   [1, 64, 56, 56]           (73,984)\n",
              "│    └─Sequential: 2-6                        [1, 128, 28, 28]          --\n",
              "│    │    └─BasicBlock: 3-4                   [1, 128, 28, 28]          (230,144)\n",
              "│    │    └─BasicBlock: 3-5                   [1, 128, 28, 28]          (295,424)\n",
              "│    │    └─BasicBlock: 3-6                   [1, 128, 28, 28]          (295,424)\n",
              "│    │    └─BasicBlock: 3-7                   [1, 128, 28, 28]          (295,424)\n",
              "│    └─Sequential: 2-7                        [1, 256, 14, 14]          --\n",
              "│    │    └─BasicBlock: 3-8                   [1, 256, 14, 14]          (919,040)\n",
              "│    │    └─BasicBlock: 3-9                   [1, 256, 14, 14]          (1,180,672)\n",
              "│    │    └─BasicBlock: 3-10                  [1, 256, 14, 14]          (1,180,672)\n",
              "│    │    └─BasicBlock: 3-11                  [1, 256, 14, 14]          (1,180,672)\n",
              "│    │    └─BasicBlock: 3-12                  [1, 256, 14, 14]          (1,180,672)\n",
              "│    │    └─BasicBlock: 3-13                  [1, 256, 14, 14]          (1,180,672)\n",
              "│    └─Sequential: 2-8                        [1, 512, 7, 7]            --\n",
              "│    │    └─BasicBlock: 3-14                  [1, 512, 7, 7]            (3,673,088)\n",
              "│    │    └─BasicBlock: 3-15                  [1, 512, 7, 7]            (4,720,640)\n",
              "│    │    └─BasicBlock: 3-16                  [1, 512, 7, 7]            (4,720,640)\n",
              "├─AdaptiveAvgPool2d: 1-2                      [1, 512, 1, 1]            --\n",
              "├─Rearrange: 1-3                              [1, 512]                  --\n",
              "├─Sequential: 1-4                             [1, 3]                    --\n",
              "│    └─Linear: 2-9                            [1, 512]                  262,656\n",
              "│    └─ReLU: 2-10                             [1, 512]                  --\n",
              "│    └─BatchNorm1d: 2-11                      [1, 512]                  1,024\n",
              "│    └─Linear: 2-12                           [1, 3]                    1,539\n",
              "===============================================================================================\n",
              "Total params: 21,543,619\n",
              "Trainable params: 265,219\n",
              "Non-trainable params: 21,278,400\n",
              "Total mult-adds (G): 3.58\n",
              "===============================================================================================\n",
              "Input size (MB): 0.20\n",
              "Forward/backward pass size (MB): 59.82\n",
              "Params size (MB): 86.17\n",
              "Estimated Total Size (MB): 146.19\n",
              "==============================================================================================="
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "backbone = nn.Sequential(*list(model.backbone.children())[:-1])\n",
        "\n",
        "finetune_model = FinetuneClassifier(backbone, classification_head)\n",
        "finetune_model.to(device)\n",
        "summary(finetune_model, input_size=(1, 1, 224, 224), device=\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "learning_rate = 3e-4\n",
        "weight_decay =  0.01\n",
        "\n",
        "finetune_optimizer = optim.AdamW(\n",
        "    finetune_model.parameters(),\n",
        "    lr=learning_rate,\n",
        "    weight_decay=weight_decay,\n",
        ")\n",
        "\n",
        "finetune_epochs = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "finetuned_model_path = \"logger/colab/CrossFormer_finetuned_II_2023-07-31-23-14-06.pt\"\n",
        "finetune_criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "def finetune(\n",
        "    epochs: int,\n",
        "    model: nn.Module,\n",
        "    device: Union[int, str],\n",
        "    train_loader: Any,\n",
        "    criterion: nn.Module,\n",
        "    optimizer: nn.Module,\n",
        "    saved_model_path: str,\n",
        "    valid_loader: Any,\n",
        "):\n",
        "    best_loss = float(\"inf\")\n",
        "    all_val_loss = []\n",
        "    all_val_accuracy = []\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0.0\n",
        "        model.train()\n",
        "\n",
        "        for batch_idx, (img1, _, label) in enumerate(train_loader):\n",
        "            img1 = img1.to(device)\n",
        "            label = label.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(img1)\n",
        "\n",
        "            loss = criterion(output, label)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss\n",
        "\n",
        "            if batch_idx % 10 == 0:\n",
        "                print(\n",
        "                    f\"Epoch [{epoch}/{epochs}], Batch [{batch_idx}/{len(train_loader)}], Loss: {loss.item()}\"\n",
        "                )\n",
        "\n",
        "        epoch_loss = epoch_loss / len(train_loader)\n",
        "\n",
        "        if epoch_loss < best_loss:\n",
        "            best_loss = epoch_loss\n",
        "            best_model = copy.deepcopy(model)\n",
        "            torch.save(best_model.state_dict(), saved_model_path)\n",
        "            print(\"====== Model saved ======\")\n",
        "\n",
        "        with torch.no_grad():\n",
        "            print(\"====== Eval started ======\")\n",
        "            model.eval()\n",
        "            epoch_val_accuracy = 0\n",
        "            epoch_val_loss = 0\n",
        "            for _, (data, _, label) in enumerate(valid_loader):\n",
        "                data = data.to(device)\n",
        "                label = label.to(device)\n",
        "\n",
        "                val_output = model(data)\n",
        "                val_loss = criterion(val_output, label)\n",
        "\n",
        "                acc = (val_output.argmax(dim=1) == label).float().mean()\n",
        "                epoch_val_accuracy += acc\n",
        "                epoch_val_loss += val_loss\n",
        "\n",
        "            epoch_val_accuracy = epoch_val_accuracy / len(valid_loader)\n",
        "            epoch_val_loss = epoch_val_loss / len(valid_loader)\n",
        "            all_val_loss.append(epoch_val_loss)\n",
        "\n",
        "        all_val_accuracy.append(epoch_val_accuracy.item() * 100)\n",
        "\n",
        "        print(\n",
        "            f\"Epoch : {epoch+1} - loss : {epoch_loss:.4f} - val_loss : {epoch_val_loss:.4f} - val_acc: {epoch_val_accuracy:.4f} \\n\"\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [0/10], Batch [0/131], Loss: 1.156130075454712\n",
            "Epoch [0/10], Batch [10/131], Loss: 1.0891685485839844\n",
            "Epoch [0/10], Batch [20/131], Loss: 1.0873832702636719\n",
            "Epoch [0/10], Batch [30/131], Loss: 1.0675220489501953\n",
            "Epoch [0/10], Batch [40/131], Loss: 1.0510790348052979\n",
            "Epoch [0/10], Batch [50/131], Loss: 1.0583583116531372\n",
            "Epoch [0/10], Batch [60/131], Loss: 1.0402311086654663\n",
            "Epoch [0/10], Batch [70/131], Loss: 1.0362662076950073\n",
            "Epoch [0/10], Batch [80/131], Loss: 1.0036343336105347\n",
            "Epoch [0/10], Batch [90/131], Loss: 1.0043225288391113\n",
            "Epoch [0/10], Batch [100/131], Loss: 0.9899460077285767\n",
            "Epoch [0/10], Batch [110/131], Loss: 1.022749900817871\n",
            "Epoch [0/10], Batch [120/131], Loss: 0.9831846952438354\n",
            "Epoch [0/10], Batch [130/131], Loss: 0.9697375893592834\n",
            "====== Model saved ======\n",
            "====== Eval started ======\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 1 - loss : 1.0382 - val_loss : 0.9736 - val_acc: 0.5581 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Batch [0/131], Loss: 0.9611487984657288\n",
            "Epoch [1/10], Batch [10/131], Loss: 0.9817225933074951\n",
            "Epoch [1/10], Batch [20/131], Loss: 0.9751446843147278\n",
            "Epoch [1/10], Batch [30/131], Loss: 0.9753904342651367\n",
            "Epoch [1/10], Batch [40/131], Loss: 0.96584153175354\n",
            "Epoch [1/10], Batch [50/131], Loss: 0.9561709761619568\n",
            "Epoch [1/10], Batch [60/131], Loss: 0.9418426156044006\n",
            "Epoch [1/10], Batch [70/131], Loss: 0.9123293161392212\n",
            "Epoch [1/10], Batch [80/131], Loss: 0.8984346389770508\n",
            "Epoch [1/10], Batch [90/131], Loss: 0.9128507375717163\n",
            "Epoch [1/10], Batch [100/131], Loss: 0.9051358699798584\n",
            "Epoch [1/10], Batch [110/131], Loss: 0.930675208568573\n",
            "Epoch [1/10], Batch [120/131], Loss: 0.9230825901031494\n",
            "Epoch [1/10], Batch [130/131], Loss: 0.8869390487670898\n",
            "====== Model saved ======\n",
            "====== Eval started ======\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 2 - loss : 0.9360 - val_loss : 0.9401 - val_acc: 0.5255 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Batch [0/131], Loss: 0.9224660396575928\n",
            "Epoch [2/10], Batch [10/131], Loss: 0.8705552816390991\n",
            "Epoch [2/10], Batch [20/131], Loss: 0.8635736107826233\n",
            "Epoch [2/10], Batch [30/131], Loss: 0.8560745120048523\n",
            "Epoch [2/10], Batch [40/131], Loss: 0.9219212532043457\n",
            "Epoch [2/10], Batch [50/131], Loss: 0.8758096098899841\n",
            "Epoch [2/10], Batch [60/131], Loss: 0.9059553742408752\n",
            "Epoch [2/10], Batch [70/131], Loss: 0.901246964931488\n",
            "Epoch [2/10], Batch [80/131], Loss: 0.8741222023963928\n",
            "Epoch [2/10], Batch [90/131], Loss: 0.9042016863822937\n",
            "Epoch [2/10], Batch [100/131], Loss: 0.8902913331985474\n",
            "Epoch [2/10], Batch [110/131], Loss: 0.8757559657096863\n",
            "Epoch [2/10], Batch [120/131], Loss: 0.8550633192062378\n",
            "Epoch [2/10], Batch [130/131], Loss: 0.8385408520698547\n",
            "====== Model saved ======\n",
            "====== Eval started ======\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 3 - loss : 0.8852 - val_loss : 0.8976 - val_acc: 0.5575 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Batch [0/131], Loss: 0.8477258086204529\n",
            "Epoch [3/10], Batch [10/131], Loss: 0.8750947117805481\n",
            "Epoch [3/10], Batch [20/131], Loss: 0.8581960201263428\n",
            "Epoch [3/10], Batch [30/131], Loss: 0.8373576402664185\n",
            "Epoch [3/10], Batch [40/131], Loss: 0.8400853872299194\n",
            "Epoch [3/10], Batch [50/131], Loss: 0.8162515163421631\n",
            "Epoch [3/10], Batch [60/131], Loss: 0.8277515172958374\n",
            "Epoch [3/10], Batch [70/131], Loss: 0.8756191730499268\n",
            "Epoch [3/10], Batch [80/131], Loss: 0.8437551259994507\n",
            "Epoch [3/10], Batch [90/131], Loss: 0.8206300735473633\n",
            "Epoch [3/10], Batch [100/131], Loss: 0.8415161371231079\n",
            "Epoch [3/10], Batch [110/131], Loss: 0.8542090654373169\n",
            "Epoch [3/10], Batch [120/131], Loss: 0.8285565376281738\n",
            "Epoch [3/10], Batch [130/131], Loss: 0.8470039367675781\n",
            "====== Model saved ======\n",
            "====== Eval started ======\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 4 - loss : 0.8529 - val_loss : 0.8992 - val_acc: 0.5588 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Batch [0/131], Loss: 0.8547733426094055\n",
            "Epoch [4/10], Batch [10/131], Loss: 0.81734299659729\n",
            "Epoch [4/10], Batch [20/131], Loss: 0.8169073462486267\n",
            "Epoch [4/10], Batch [30/131], Loss: 0.8085623979568481\n",
            "Epoch [4/10], Batch [40/131], Loss: 0.8239424228668213\n",
            "Epoch [4/10], Batch [50/131], Loss: 0.8528308272361755\n",
            "Epoch [4/10], Batch [60/131], Loss: 0.8829872012138367\n",
            "Epoch [4/10], Batch [70/131], Loss: 0.847292423248291\n",
            "Epoch [4/10], Batch [80/131], Loss: 0.8302809000015259\n",
            "Epoch [4/10], Batch [90/131], Loss: 0.825409471988678\n",
            "Epoch [4/10], Batch [100/131], Loss: 0.868257462978363\n",
            "Epoch [4/10], Batch [110/131], Loss: 0.8002006411552429\n",
            "Epoch [4/10], Batch [120/131], Loss: 0.8373543620109558\n",
            "Epoch [4/10], Batch [130/131], Loss: 0.8580778241157532\n",
            "====== Model saved ======\n",
            "====== Eval started ======\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 5 - loss : 0.8316 - val_loss : 0.8505 - val_acc: 0.5912 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Batch [0/131], Loss: 0.8453021049499512\n",
            "Epoch [5/10], Batch [10/131], Loss: 0.8118219971656799\n",
            "Epoch [5/10], Batch [20/131], Loss: 0.8211382627487183\n",
            "Epoch [5/10], Batch [30/131], Loss: 0.7973555326461792\n",
            "Epoch [5/10], Batch [40/131], Loss: 0.8319476842880249\n",
            "Epoch [5/10], Batch [50/131], Loss: 0.7941102981567383\n",
            "Epoch [5/10], Batch [60/131], Loss: 0.8466867804527283\n",
            "Epoch [5/10], Batch [70/131], Loss: 0.7994270920753479\n",
            "Epoch [5/10], Batch [80/131], Loss: 0.8073349595069885\n",
            "Epoch [5/10], Batch [90/131], Loss: 0.7666801810264587\n",
            "Epoch [5/10], Batch [100/131], Loss: 0.7723305821418762\n",
            "Epoch [5/10], Batch [110/131], Loss: 0.7985684871673584\n",
            "Epoch [5/10], Batch [120/131], Loss: 0.7708105444908142\n",
            "Epoch [5/10], Batch [130/131], Loss: 0.851091206073761\n",
            "====== Model saved ======\n",
            "====== Eval started ======\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 6 - loss : 0.8086 - val_loss : 0.8141 - val_acc: 0.6016 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Batch [0/131], Loss: 0.8009103536605835\n",
            "Epoch [6/10], Batch [10/131], Loss: 0.814725935459137\n",
            "Epoch [6/10], Batch [20/131], Loss: 0.7795451879501343\n",
            "Epoch [6/10], Batch [30/131], Loss: 0.8139488697052002\n",
            "Epoch [6/10], Batch [40/131], Loss: 0.8131596446037292\n",
            "Epoch [6/10], Batch [50/131], Loss: 0.8241100907325745\n",
            "Epoch [6/10], Batch [60/131], Loss: 0.7481332421302795\n",
            "Epoch [6/10], Batch [70/131], Loss: 0.812390148639679\n",
            "Epoch [6/10], Batch [80/131], Loss: 0.8005272746086121\n",
            "Epoch [6/10], Batch [90/131], Loss: 0.8238431215286255\n",
            "Epoch [6/10], Batch [100/131], Loss: 0.8032150864601135\n",
            "Epoch [6/10], Batch [110/131], Loss: 0.8012538552284241\n"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "finetune(\n",
        "    finetune_epochs,\n",
        "    finetune_model,\n",
        "    device,\n",
        "    train_loader,\n",
        "    finetune_criterion,\n",
        "    finetune_optimizer,\n",
        "    finetuned_model_path,\n",
        "    valid_loader=val_loader,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "vVWofjN-Sp6f"
      },
      "source": [
        "# New Section"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
