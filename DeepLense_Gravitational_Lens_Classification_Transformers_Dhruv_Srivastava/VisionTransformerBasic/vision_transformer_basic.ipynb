{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "X7Ekxmo1XV5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mFRKD8F__hl",
        "outputId": "0495f67f-8d6b-4160-c594-cceaab989d2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/drive/MyDrive/Model_III_data/Model_III/axion\n",
        "!ls -1q /content/drive/MyDrive/Model_III_data/Model_III/no_sub | wc -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMbel4LB8oLb",
        "outputId": "7cc98f45-8719-4e02-c747-c15d4c1ff05c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/Model_III_data/Model_III/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9l0m91pCBpI1",
        "outputId": "483f3706-70d6-4eaf-efaf-23bb1238f35a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access '/content/drive/MyDrive/Model_III_data/Model_III/': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Extract tarfile\n",
        "import shutil\n",
        "shutil.unpack_archive('/content/drive/MyDrive/Model_III.tgz', '/content/drive/MyDrive/Model_III_dataset')"
      ],
      "metadata": {
        "id": "_HwTHNYYAoBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRM2kxST8KJZ"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "GSoC 2025 Internship Application Task - 1\n",
        "Author: Dhruv Srivastava\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"Import dependencies\"\"\"\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.models import resnet18\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Dm6SC1o_txB"
      },
      "outputs": [],
      "source": [
        "\"\"\"Define Dataset Class for Vision Transformer with Debugging\"\"\"\n",
        "class MyDatasetViT(Dataset):\n",
        "    def __init__(self, data_dir, transform=None):\n",
        "        self.data = []\n",
        "        self.labels = []\n",
        "        self.class_names = ['axion', 'cdm', 'no_sub']\n",
        "        self.transform = transform\n",
        "\n",
        "        print(f\"Loading dataset from: {data_dir}\")\n",
        "        print(f\"Looking for classes: {self.class_names}\")\n",
        "\n",
        "        for idx, class_name in enumerate(self.class_names):\n",
        "            class_dir = os.path.join(data_dir, class_name)\n",
        "            print(f\"--- Processing class: {class_name} ---\")\n",
        "\n",
        "            if not os.path.exists(class_dir):\n",
        "                print(f\"[ERROR] Directory not found: {class_dir}\")\n",
        "                continue\n",
        "\n",
        "            files = os.listdir(class_dir)\n",
        "\n",
        "            for file_name in files:\n",
        "                if file_name.endswith('.npy'):\n",
        "                    file_path = os.path.join(class_dir, file_name)\n",
        "                    loaded_data = np.load(file_path, allow_pickle=True)\n",
        "\n",
        "                    if class_name == 'axion':\n",
        "                        image = loaded_data[0]\n",
        "                    else:\n",
        "                        image = loaded_data\n",
        "\n",
        "                    # [DEBUG] Print the shape of the raw numpy array\n",
        "                    print(f\"  [DEBUG] Loaded '{file_name}'. Raw numpy shape: {image.shape}\")\n",
        "\n",
        "                    # Ensure the image is a 2D array (H, W) before adding channel dimension.\n",
        "                    if image.ndim != 2:\n",
        "                        image = np.squeeze(image)\n",
        "\n",
        "                    # Convert to a float tensor and add a channel dimension -> [1, H, W]\n",
        "                    image_tensor = torch.tensor(image, dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "                    # [DEBUG] Print the shape of the final tensor being stored in the dataset\n",
        "                    print(f\"  [DEBUG] Storing tensor with final shape: {image_tensor.shape}\\n\")\n",
        "\n",
        "                    self.data.append(image_tensor)\n",
        "                    self.labels.append(idx)\n",
        "\n",
        "        print(\"\\n--- Dataset Loading Complete ---\")\n",
        "        print(f\"Total images loaded: {len(self.data)}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        This method is called by the DataLoader to get one item from the dataset.\n",
        "        The debug prints here are CRITICAL for finding the error.\n",
        "        \"\"\"\n",
        "        #print(f\"--- Getting item index: {idx} ---\")\n",
        "\n",
        "        # Retrieve the pre-loaded tensor and its label\n",
        "        image = self.data[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # [DEBUG] Print shape BEFORE the transform is applied\n",
        "        #print(f\"  [DEBUG] Shape of tensor BEFORE transform: {image.shape}\")\n",
        "\n",
        "        # Apply transformations (e.g., resizing) if they are provided\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "            # [DEBUG] Print shape AFTER the transform is applied\n",
        "            #print(f\"  [DEBUG] Shape of tensor AFTER transform: {image.shape}\")\n",
        "        else:\n",
        "            #print(\"  [DEBUG] No transform was applied.\")\n",
        "            pass\n",
        "\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJEgowwT_txC",
        "outputId": "de7672d2-1191-4930-adc3-37c424d0ad7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Directory: /content/drive/MyDrive/Model_III_dataset/Model_III\n"
          ]
        }
      ],
      "source": [
        "# Import the transforms module\n",
        "from torchvision import transforms\n",
        "# Hyperparameters\n",
        "batch_size = 32\n",
        "learning_rate = 0.001\n",
        "num_epochs = 100\n",
        "\n",
        "# Data Directories\n",
        "train_dir = '/content/drive/MyDrive/Model_III_dataset/Model_III'\n",
        "#val_dir = '../dataset/dataset/val'\n",
        "\n",
        "print(f\"Training Directory: {train_dir}\")\n",
        "#print(f\"Validation Directory: {val_dir}\")\n",
        "\n",
        "vit_transforms = transforms.Compose([\n",
        "    transforms.Resize((64, 64), antialias=True)\n",
        "])\n",
        "\n",
        "# Create Datasets and Dataloaders\n",
        "#train_dataset = MyDataset(train_dir)\n",
        "#val_dataset = MyDataset(val_dir)\n",
        "#dataset = MyDatasetViT(train_dir, vit_transforms)\n",
        "#train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [0.75, 0.15, 0.1])\n",
        "\n",
        "#train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
        "#val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=4, pin_memory=True)\n",
        "\n",
        "#print(f\"Batch Size: {batch_size}\")\n",
        "#print(f\"Number of Training Batches: {len(train_loader)}\")\n",
        "#print(f\"Number of Validation Batches: {len(val_loader)}\")\n",
        "\n",
        "#Save the dataloader so that we don't have to bear with this pain again\n",
        "#torch.save(train_loader, '/content/drive/MyDrive/Model_III_dataset/train_loader.pth')\n",
        "#torch.save(val_loader, '/content/drive/MyDrive/Model_III_dataset/val_loader.pth')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import data loaders from file\n",
        "train_loader = torch.load('/content/drive/MyDrive/Model_III_dataset/train_loader.pth', weights_only=False)\n",
        "val_loader = torch.load('/content/drive/MyDrive/Model_III_dataset/val_loader.pth', weights_only=False)"
      ],
      "metadata": {
        "id": "gvqsjdgzKmOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6Q9I1Hw_txD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cbb9dc6-5dc1-4d81-cc79-3feb9bd3cf9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from timm.models.layers import DropPath\n",
        "\n",
        "class PatchEmbedding(nn.Module):\n",
        "    def __init__(self, image_size, patch_size, in_channels, embed_dim):\n",
        "        super().__init__()\n",
        "        self.image_size = image_size\n",
        "        self.patch_size = patch_size\n",
        "        self.num_patches = (image_size // patch_size) ** 2\n",
        "\n",
        "        self.projection = nn.Conv2d(\n",
        "            in_channels,\n",
        "            embed_dim,\n",
        "            kernel_size=patch_size,\n",
        "            stride=patch_size\n",
        "        )\n",
        "\n",
        "        self.cls_token = nn.Parameter(torch.randn(1, 1, embed_dim))\n",
        "        self.positional_embedding = nn.Parameter(torch.randn(1, self.num_patches + 1, embed_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # (B, C, H, W) -> (B, E, N_patches_sqrt, N_patches_sqrt)\n",
        "        x = self.projection(x)\n",
        "        # (B, E, N_patches_sqrt, N_patches_sqrt) -> (B, E, N)\n",
        "        x = x.flatten(2)\n",
        "        # (B, E, N) -> (B, N, E)\n",
        "        x = x.transpose(1, 2)\n",
        "\n",
        "        # --- FIX IS HERE ---\n",
        "        # Get the batch size from the input tensor x\n",
        "        batch_size = x.shape[0]\n",
        "        # Expand the CLS token to match the batch size\n",
        "        cls_tokens = self.cls_token.expand(batch_size, -1, -1)\n",
        "\n",
        "        # Prepend the CLS token to the patch embeddings\n",
        "        x = torch.cat((cls_tokens, x), dim=1)\n",
        "\n",
        "        # Add positional embeddings\n",
        "        x = x + self.positional_embedding\n",
        "\n",
        "        return x\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads, dropout=0.1):\n",
        "        super().__init__()\n",
        "        assert embed_dim % num_heads == 0, \"Embedding dimension must be divisible by number of heads.\"\n",
        "\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = embed_dim // num_heads\n",
        "        self.scale = self.head_dim ** -0.5\n",
        "\n",
        "        self.qkv = nn.Linear(embed_dim, embed_dim * 3)\n",
        "        self.attn_dropout = nn.Dropout(dropout)\n",
        "        self.proj = nn.Linear(embed_dim, embed_dim)\n",
        "        self.proj_dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, C = x.shape\n",
        "\n",
        "        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, self.head_dim).permute(2, 0, 3, 1, 4)\n",
        "\n",
        "        # --- FIX IS HERE ---\n",
        "        # Unpack q, k, v from the first dimension\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
        "\n",
        "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
        "        attn = attn.softmax(dim=-1)\n",
        "        attn = self.attn_dropout(attn)\n",
        "\n",
        "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
        "\n",
        "        x = self.proj(x)\n",
        "        x = self.proj_dropout(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features, out_features, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
        "        self.act = nn.GELU()\n",
        "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "class TransformerEncoderBlock(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads, mlp_ratio=4.0, dropout=0.1, drop_path_rate=0.0):\n",
        "        super().__init__()\n",
        "        self.norm1 = nn.LayerNorm(embed_dim)\n",
        "        self.attn = MultiHeadAttention(embed_dim, num_heads, dropout)\n",
        "        self.norm2 = nn.LayerNorm(embed_dim)\n",
        "        mlp_hidden_dim = int(embed_dim * mlp_ratio)\n",
        "        self.mlp = MLP(in_features=embed_dim, hidden_features=mlp_hidden_dim, out_features=embed_dim, dropout=dropout)\n",
        "        self.drop_path = DropPath(drop_path_rate) if drop_path_rate > 0. else nn.Identity()\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.drop_path(self.attn(self.norm1(x)))\n",
        "        x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
        "        return x\n",
        "\n",
        "class VisionTransformer(nn.Module):\n",
        "    def __init__(self, image_size=224, patch_size=16, in_channels=1, num_classes=3,\n",
        "                 embed_dim=768, depth=12, num_heads=12, mlp_ratio=4.0, dropout=0.1, drop_path_rate = 0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.patch_embed = PatchEmbedding(image_size, patch_size, in_channels, embed_dim)\n",
        "\n",
        "        dpr = [x.item() for x in torch.linspace(0, drop_path_rate, depth)]\n",
        "\n",
        "        self.encoder_blocks = nn.ModuleList([\n",
        "            TransformerEncoderBlock(\n",
        "                embed_dim=embed_dim,\n",
        "                num_heads=num_heads,\n",
        "                mlp_ratio=mlp_ratio,\n",
        "                dropout=dropout,\n",
        "                drop_path_rate = dpr[i]\n",
        "            ) for i in range(depth)])\n",
        "\n",
        "        self.norm = nn.LayerNorm(embed_dim)\n",
        "        self.head = nn.Linear(embed_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.patch_embed(x)\n",
        "\n",
        "        for block in self.encoder_blocks:\n",
        "            x = block(x)\n",
        "\n",
        "        x = self.norm(x)\n",
        "\n",
        "        cls_token_final = x[:, 0]\n",
        "        output = self.head(cls_token_final)\n",
        "\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install torch_xla[tpu]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hivvAHcI41JJ",
        "outputId": "257c8cec-1eba-478e-ca04-286fede0f97c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_xla[tpu]\n",
            "  Downloading torch_xla-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (21 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from torch_xla[tpu]) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_xla[tpu]) (2.0.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from torch_xla[tpu]) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_xla[tpu]) (2.32.3)\n",
            "Collecting libtpu==0.0.11.1 (from torch_xla[tpu])\n",
            "  Downloading libtpu-0.0.11.1-py3-none-manylinux_2_31_x86_64.whl.metadata (556 bytes)\n",
            "Collecting tpu-info (from torch_xla[tpu])\n",
            "  Downloading tpu_info-0.3.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: grpcio>=1.65.5 in /usr/local/lib/python3.11/dist-packages (from tpu-info->torch_xla[tpu]) (1.73.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from tpu-info->torch_xla[tpu]) (5.29.5)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from tpu-info->torch_xla[tpu]) (13.9.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_xla[tpu]) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_xla[tpu]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_xla[tpu]) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_xla[tpu]) (2025.6.15)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->tpu-info->torch_xla[tpu]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->tpu-info->torch_xla[tpu]) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->tpu-info->torch_xla[tpu]) (0.1.2)\n",
            "Downloading libtpu-0.0.11.1-py3-none-manylinux_2_31_x86_64.whl (130.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.4/130.4 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tpu_info-0.3.0-py3-none-any.whl (15 kB)\n",
            "Downloading torch_xla-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl (96.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.6/96.6 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_xla, tpu-info, libtpu\n",
            "Successfully installed libtpu-0.0.11.1 torch_xla-2.7.0 tpu-info-0.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import torch_xla"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "GtiRNfT34-6a",
        "outputId": "c9533c3a-f67e-4fcd-fce4-a4af6e412ce4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "/usr/local/lib/python3.11/dist-packages/_XLAC.cpython-311-x86_64-linux-gnu.so: undefined symbol: _ZN5torch4lazy13MetricFnValueB5cxx11Ed",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-14-846170711.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_xla\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_xla/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdlopenflags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0m_XLAC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_internal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtpu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: /usr/local/lib/python3.11/dist-packages/_XLAC.cpython-311-x86_64-linux-gnu.so: undefined symbol: _ZN5torch4lazy13MetricFnValueB5cxx11Ed",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3rnNlt1_txE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import copy\n",
        "\n",
        "\"\"\"Training and Evaluation with Early Stopping\"\"\"\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=50, patience=10):\n",
        "    \"\"\"\n",
        "    Trains the model with early stopping based on validation ROC AUC score.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): The neural network model to train.\n",
        "        train_loader (torch.utils.data.DataLoader): DataLoader for the training set.\n",
        "        val_loader (torch.utils.data.DataLoader): DataLoader for the validation set.\n",
        "        criterion: The loss function.\n",
        "        optimizer: The optimization algorithm.\n",
        "        scheduler: The learning rate scheduler.\n",
        "        num_epochs (int): The maximum number of epochs to train for.\n",
        "        patience (int): Number of epochs to wait for improvement before stopping.\n",
        "    \"\"\"\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Training on device: {device}\")\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    best_roc_auc = 0.0\n",
        "    epochs_no_improve = 0\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    class_names = ['axion', 'cdm', 'no_sub']\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\\n===== Epoch {epoch+1}/{num_epochs} =====\")\n",
        "\n",
        "        # --- Training Phase ---\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        train_correct = 0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            train_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # --- Validation Phase ---\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_correct = 0\n",
        "        all_probs = []\n",
        "        all_labels = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                val_loss += loss.item() * images.size(0)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "                probs = torch.softmax(outputs, dim=1)\n",
        "                all_probs.extend(probs.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        # --- Calculate Metrics ---\n",
        "        train_loss = train_loss / len(train_loader.dataset)\n",
        "        val_loss = val_loss / len(val_loader.dataset)\n",
        "        train_accuracy = train_correct / len(train_loader.dataset)\n",
        "        val_accuracy = val_correct / len(val_loader.dataset)\n",
        "\n",
        "        # Calculate multi-class ROC AUC score\n",
        "        all_labels_np = np.array(all_labels)\n",
        "        all_probs_np = np.array(all_probs)\n",
        "        try:\n",
        "            val_roc_auc = roc_auc_score(all_labels_np, all_probs_np, multi_class='ovr', average='macro')\n",
        "        except ValueError as e:\n",
        "            print(f\"Could not calculate ROC AUC: {e}\")\n",
        "            val_roc_auc = 0.0\n",
        "\n",
        "        # Epoch-level summary\n",
        "        print(f'\\n[SUMMARY] Epoch {epoch+1}/{num_epochs}:')\n",
        "        print(f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}')\n",
        "        print(f'Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}, Val ROC AUC: {val_roc_auc:.4f}')\n",
        "\n",
        "        if val_roc_auc > best_roc_auc:\n",
        "            best_roc_auc = val_roc_auc\n",
        "            epochs_no_improve = 0\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            torch.save(model.state_dict(), '/content/drive/MyDrive/Model_III_dataset/lens_classifier_model_vision_transformer.pth')\n",
        "            print(f\"New best model saved with Val ROC AUC: {best_roc_auc:.4f}\")\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            print(f\"No improvement in Val ROC AUC for {epochs_no_improve} epoch(s). Best is {best_roc_auc:.4f}.\")\n",
        "\n",
        "        if epochs_no_improve >= patience:\n",
        "            print(f\"\\nEarly stopping triggered after {patience} epochs without improvement.\")\n",
        "            model.load_state_dict(best_model_wts)\n",
        "            break\n",
        "\n",
        "    print(\"\\nTraining Complete!\")\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, all_probs, all_labels"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#torch.save(model.state_dict(), '/content/drive/MyDrive/Model_III_dataset/model_weights.pth')"
      ],
      "metadata": {
        "id": "9QBIRCLEkikD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "91f23758-e1e5-4da6-da2c-c68f6ff45595"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-9-2106813171.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/drive/MyDrive/Model_III_dataset/model_weights.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZJepKUw_txF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb8cea1e-a600-45a2-f604-6052f8bbff56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimizer: Adam\n",
            "Learning Rate: 0.0005\n",
            "Training on device: cuda\n",
            "\n",
            "===== Epoch 1/200 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[SUMMARY] Epoch 1/200:\n",
            "Train Loss: 0.9092, Train Accuracy: 0.4850\n",
            "Val Loss: 0.5946, Val Accuracy: 0.6748, Val ROC AUC: 0.8394\n",
            "✅ New best model saved with Val ROC AUC: 0.8394\n",
            "\n",
            "===== Epoch 2/200 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[SUMMARY] Epoch 2/200:\n",
            "Train Loss: 0.6260, Train Accuracy: 0.6503\n",
            "Val Loss: 0.5740, Val Accuracy: 0.6807, Val ROC AUC: 0.8549\n",
            "✅ New best model saved with Val ROC AUC: 0.8549\n",
            "\n",
            "===== Epoch 3/200 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[SUMMARY] Epoch 3/200:\n",
            "Train Loss: 0.5810, Train Accuracy: 0.6884\n",
            "Val Loss: 0.5053, Val Accuracy: 0.7443, Val ROC AUC: 0.8966\n",
            "✅ New best model saved with Val ROC AUC: 0.8966\n",
            "\n",
            "===== Epoch 4/200 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[SUMMARY] Epoch 4/200:\n",
            "Train Loss: 0.5559, Train Accuracy: 0.7091\n",
            "Val Loss: 0.6880, Val Accuracy: 0.6322, Val ROC AUC: 0.8330\n",
            "⚠️ No improvement in Val ROC AUC for 1 epoch(s). Best is 0.8966.\n",
            "\n",
            "===== Epoch 5/200 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[SUMMARY] Epoch 5/200:\n",
            "Train Loss: 0.5240, Train Accuracy: 0.7328\n",
            "Val Loss: 0.4144, Val Accuracy: 0.8163, Val ROC AUC: 0.9383\n",
            "✅ New best model saved with Val ROC AUC: 0.9383\n",
            "\n",
            "===== Epoch 6/200 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[SUMMARY] Epoch 6/200:\n",
            "Train Loss: 0.4963, Train Accuracy: 0.7604\n",
            "Val Loss: 0.4904, Val Accuracy: 0.7703, Val ROC AUC: 0.9138\n",
            "⚠️ No improvement in Val ROC AUC for 1 epoch(s). Best is 0.9383.\n",
            "\n",
            "===== Epoch 7/200 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[SUMMARY] Epoch 7/200:\n",
            "Train Loss: 0.4268, Train Accuracy: 0.8049\n",
            "Val Loss: 0.2687, Val Accuracy: 0.8956, Val ROC AUC: 0.9759\n",
            "✅ New best model saved with Val ROC AUC: 0.9759\n",
            "\n",
            "===== Epoch 8/200 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[SUMMARY] Epoch 8/200:\n",
            "Train Loss: 0.3901, Train Accuracy: 0.8346\n",
            "Val Loss: 0.4528, Val Accuracy: 0.8038, Val ROC AUC: 0.9345\n",
            "⚠️ No improvement in Val ROC AUC for 1 epoch(s). Best is 0.9759.\n",
            "\n",
            "===== Epoch 9/200 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[SUMMARY] Epoch 9/200:\n",
            "Train Loss: 0.3253, Train Accuracy: 0.8665\n",
            "Val Loss: 0.1956, Val Accuracy: 0.9268, Val ROC AUC: 0.9869\n",
            "✅ New best model saved with Val ROC AUC: 0.9869\n",
            "\n",
            "===== Epoch 10/200 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[SUMMARY] Epoch 10/200:\n",
            "Train Loss: 0.3056, Train Accuracy: 0.8774\n",
            "Val Loss: 0.2845, Val Accuracy: 0.8890, Val ROC AUC: 0.9734\n",
            "⚠️ No improvement in Val ROC AUC for 1 epoch(s). Best is 0.9869.\n",
            "\n",
            "===== Epoch 11/200 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[SUMMARY] Epoch 11/200:\n",
            "Train Loss: 0.2788, Train Accuracy: 0.8919\n",
            "Val Loss: 0.1745, Val Accuracy: 0.9365, Val ROC AUC: 0.9903\n",
            "✅ New best model saved with Val ROC AUC: 0.9903\n",
            "\n",
            "===== Epoch 12/200 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[SUMMARY] Epoch 12/200:\n",
            "Train Loss: 0.2640, Train Accuracy: 0.8992\n",
            "Val Loss: 0.2380, Val Accuracy: 0.9133, Val ROC AUC: 0.9815\n",
            "⚠️ No improvement in Val ROC AUC for 1 epoch(s). Best is 0.9903.\n",
            "\n",
            "===== Epoch 13/200 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[SUMMARY] Epoch 13/200:\n",
            "Train Loss: 0.2433, Train Accuracy: 0.9092\n",
            "Val Loss: 0.2031, Val Accuracy: 0.9222, Val ROC AUC: 0.9870\n",
            "⚠️ No improvement in Val ROC AUC for 2 epoch(s). Best is 0.9903.\n",
            "\n",
            "===== Epoch 14/200 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[SUMMARY] Epoch 14/200:\n",
            "Train Loss: 0.2478, Train Accuracy: 0.9080\n",
            "Val Loss: 0.2844, Val Accuracy: 0.8917, Val ROC AUC: 0.9789\n",
            "⚠️ No improvement in Val ROC AUC for 3 epoch(s). Best is 0.9903.\n",
            "\n",
            "===== Epoch 15/200 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[SUMMARY] Epoch 15/200:\n",
            "Train Loss: 0.2366, Train Accuracy: 0.9119\n",
            "Val Loss: 0.1688, Val Accuracy: 0.9385, Val ROC AUC: 0.9920\n",
            "✅ New best model saved with Val ROC AUC: 0.9920\n",
            "\n",
            "===== Epoch 16/200 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[SUMMARY] Epoch 16/200:\n",
            "Train Loss: 0.2261, Train Accuracy: 0.9153\n",
            "Val Loss: 0.2232, Val Accuracy: 0.9133, Val ROC AUC: 0.9848\n",
            "⚠️ No improvement in Val ROC AUC for 1 epoch(s). Best is 0.9920.\n",
            "\n",
            "===== Epoch 17/200 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[SUMMARY] Epoch 17/200:\n",
            "Train Loss: 0.2157, Train Accuracy: 0.9201\n",
            "Val Loss: 0.1766, Val Accuracy: 0.9362, Val ROC AUC: 0.9914\n",
            "⚠️ No improvement in Val ROC AUC for 2 epoch(s). Best is 0.9920.\n",
            "\n",
            "===== Epoch 18/200 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[SUMMARY] Epoch 18/200:\n",
            "Train Loss: 0.2305, Train Accuracy: 0.9158\n",
            "Val Loss: 0.2010, Val Accuracy: 0.9263, Val ROC AUC: 0.9835\n",
            "⚠️ No improvement in Val ROC AUC for 3 epoch(s). Best is 0.9920.\n",
            "\n",
            "===== Epoch 19/200 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[SUMMARY] Epoch 19/200:\n",
            "Train Loss: 0.2231, Train Accuracy: 0.9194\n",
            "Val Loss: 0.1821, Val Accuracy: 0.9344, Val ROC AUC: 0.9900\n",
            "⚠️ No improvement in Val ROC AUC for 4 epoch(s). Best is 0.9920.\n",
            "\n",
            "===== Epoch 20/200 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[SUMMARY] Epoch 20/200:\n",
            "Train Loss: 0.2101, Train Accuracy: 0.9231\n",
            "Val Loss: 0.1596, Val Accuracy: 0.9476, Val ROC AUC: 0.9910\n",
            "⚠️ No improvement in Val ROC AUC for 5 epoch(s). Best is 0.9920.\n",
            "\n",
            "===== Epoch 21/200 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[SUMMARY] Epoch 21/200:\n",
            "Train Loss: 0.1990, Train Accuracy: 0.9277\n",
            "Val Loss: 0.1646, Val Accuracy: 0.9391, Val ROC AUC: 0.9903\n",
            "⚠️ No improvement in Val ROC AUC for 6 epoch(s). Best is 0.9920.\n",
            "\n",
            "===== Epoch 22/200 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[SUMMARY] Epoch 22/200:\n",
            "Train Loss: 0.2009, Train Accuracy: 0.9268\n",
            "Val Loss: 0.1438, Val Accuracy: 0.9483, Val ROC AUC: 0.9924\n",
            "✅ New best model saved with Val ROC AUC: 0.9924\n",
            "\n",
            "===== Epoch 23/200 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[SUMMARY] Epoch 23/200:\n",
            "Train Loss: 0.2010, Train Accuracy: 0.9278\n",
            "Val Loss: 0.2015, Val Accuracy: 0.9256, Val ROC AUC: 0.9855\n",
            "⚠️ No improvement in Val ROC AUC for 1 epoch(s). Best is 0.9924.\n",
            "\n",
            "===== Epoch 24/200 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[SUMMARY] Epoch 24/200:\n",
            "Train Loss: 0.2141, Train Accuracy: 0.9235\n",
            "Val Loss: 0.1369, Val Accuracy: 0.9529, Val ROC AUC: 0.9928\n",
            "✅ New best model saved with Val ROC AUC: 0.9928\n",
            "\n",
            "===== Epoch 25/200 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[SUMMARY] Epoch 25/200:\n",
            "Train Loss: 0.2007, Train Accuracy: 0.9269\n",
            "Val Loss: 0.2793, Val Accuracy: 0.9020, Val ROC AUC: 0.9764\n",
            "⚠️ No improvement in Val ROC AUC for 1 epoch(s). Best is 0.9928.\n",
            "\n",
            "===== Epoch 26/200 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[SUMMARY] Epoch 26/200:\n",
            "Train Loss: 0.1993, Train Accuracy: 0.9272\n",
            "Val Loss: 0.1412, Val Accuracy: 0.9520, Val ROC AUC: 0.9917\n",
            "⚠️ No improvement in Val ROC AUC for 2 epoch(s). Best is 0.9928.\n",
            "\n",
            "===== Epoch 27/200 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[SUMMARY] Epoch 27/200:\n",
            "Train Loss: 0.1817, Train Accuracy: 0.9351\n",
            "Val Loss: 0.2009, Val Accuracy: 0.9252, Val ROC AUC: 0.9843\n",
            "⚠️ No improvement in Val ROC AUC for 3 epoch(s). Best is 0.9928.\n",
            "\n",
            "===== Epoch 28/200 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[SUMMARY] Epoch 28/200:\n",
            "Train Loss: 0.2001, Train Accuracy: 0.9271\n",
            "Val Loss: 0.1242, Val Accuracy: 0.9588, Val ROC AUC: 0.9942\n",
            "✅ New best model saved with Val ROC AUC: 0.9942\n",
            "\n",
            "===== Epoch 29/200 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[SUMMARY] Epoch 29/200:\n",
            "Train Loss: 0.1764, Train Accuracy: 0.9373\n",
            "Val Loss: 0.2235, Val Accuracy: 0.9174, Val ROC AUC: 0.9841\n",
            "⚠️ No improvement in Val ROC AUC for 1 epoch(s). Best is 0.9942.\n",
            "\n",
            "===== Epoch 30/200 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[SUMMARY] Epoch 30/200:\n",
            "Train Loss: 0.1734, Train Accuracy: 0.9385\n",
            "Val Loss: 0.1251, Val Accuracy: 0.9576, Val ROC AUC: 0.9935\n",
            "⚠️ No improvement in Val ROC AUC for 2 epoch(s). Best is 0.9942.\n",
            "\n",
            "===== Epoch 31/200 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[SUMMARY] Epoch 31/200:\n",
            "Train Loss: 0.1946, Train Accuracy: 0.9306\n",
            "Val Loss: 0.2429, Val Accuracy: 0.8971, Val ROC AUC: 0.9795\n",
            "⚠️ No improvement in Val ROC AUC for 3 epoch(s). Best is 0.9942.\n",
            "\n",
            "===== Epoch 32/200 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[SUMMARY] Epoch 32/200:\n",
            "Train Loss: 0.2203, Train Accuracy: 0.9198\n",
            "Val Loss: 0.1360, Val Accuracy: 0.9487, Val ROC AUC: 0.9928\n",
            "⚠️ No improvement in Val ROC AUC for 4 epoch(s). Best is 0.9942.\n",
            "\n",
            "===== Epoch 33/200 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[SUMMARY] Epoch 33/200:\n",
            "Train Loss: 0.1714, Train Accuracy: 0.9401\n",
            "Val Loss: 0.2352, Val Accuracy: 0.9176, Val ROC AUC: 0.9870\n",
            "⚠️ No improvement in Val ROC AUC for 5 epoch(s). Best is 0.9942.\n",
            "\n",
            "===== Epoch 34/200 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[SUMMARY] Epoch 34/200:\n",
            "Train Loss: 0.1754, Train Accuracy: 0.9386\n",
            "Val Loss: 0.1072, Val Accuracy: 0.9616, Val ROC AUC: 0.9961\n",
            "✅ New best model saved with Val ROC AUC: 0.9961\n",
            "\n",
            "===== Epoch 35/200 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[SUMMARY] Epoch 35/200:\n",
            "Train Loss: 0.1649, Train Accuracy: 0.9426\n",
            "Val Loss: 0.2433, Val Accuracy: 0.9060, Val ROC AUC: 0.9815\n",
            "⚠️ No improvement in Val ROC AUC for 1 epoch(s). Best is 0.9961.\n",
            "\n",
            "===== Epoch 36/200 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[SUMMARY] Epoch 36/200:\n",
            "Train Loss: 0.1713, Train Accuracy: 0.9398\n",
            "Val Loss: 0.1205, Val Accuracy: 0.9581, Val ROC AUC: 0.9943\n",
            "⚠️ No improvement in Val ROC AUC for 2 epoch(s). Best is 0.9961.\n",
            "\n",
            "===== Epoch 37/200 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[SUMMARY] Epoch 37/200:\n",
            "Train Loss: 0.1671, Train Accuracy: 0.9412\n",
            "Val Loss: 0.2016, Val Accuracy: 0.9250, Val ROC AUC: 0.9878\n",
            "⚠️ No improvement in Val ROC AUC for 3 epoch(s). Best is 0.9961.\n",
            "\n",
            "===== Epoch 38/200 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[SUMMARY] Epoch 38/200:\n",
            "Train Loss: 0.1550, Train Accuracy: 0.9458\n",
            "Val Loss: 0.1049, Val Accuracy: 0.9635, Val ROC AUC: 0.9955\n",
            "⚠️ No improvement in Val ROC AUC for 4 epoch(s). Best is 0.9961.\n",
            "\n",
            "===== Epoch 39/200 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[SUMMARY] Epoch 39/200:\n",
            "Train Loss: 0.1474, Train Accuracy: 0.9490\n",
            "Val Loss: 0.2036, Val Accuracy: 0.9350, Val ROC AUC: 0.9849\n",
            "⚠️ No improvement in Val ROC AUC for 5 epoch(s). Best is 0.9961.\n",
            "\n",
            "===== Epoch 40/200 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[SUMMARY] Epoch 40/200:\n",
            "Train Loss: 0.1433, Train Accuracy: 0.9510\n",
            "Val Loss: 0.0847, Val Accuracy: 0.9712, Val ROC AUC: 0.9970\n",
            "✅ New best model saved with Val ROC AUC: 0.9970\n",
            "\n",
            "===== Epoch 41/200 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[SUMMARY] Epoch 41/200:\n",
            "Train Loss: 0.1556, Train Accuracy: 0.9459\n",
            "Val Loss: 0.1377, Val Accuracy: 0.9508, Val ROC AUC: 0.9931\n",
            "⚠️ No improvement in Val ROC AUC for 1 epoch(s). Best is 0.9970.\n",
            "\n",
            "===== Epoch 42/200 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[SUMMARY] Epoch 42/200:\n",
            "Train Loss: 0.1400, Train Accuracy: 0.9517\n",
            "Val Loss: 0.1029, Val Accuracy: 0.9661, Val ROC AUC: 0.9950\n",
            "⚠️ No improvement in Val ROC AUC for 2 epoch(s). Best is 0.9970.\n",
            "\n",
            "===== Epoch 43/200 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[SUMMARY] Epoch 43/200:\n",
            "Train Loss: 0.1454, Train Accuracy: 0.9503\n",
            "Val Loss: 0.2245, Val Accuracy: 0.9220, Val ROC AUC: 0.9888\n",
            "⚠️ No improvement in Val ROC AUC for 3 epoch(s). Best is 0.9970.\n",
            "\n",
            "===== Epoch 44/200 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[SUMMARY] Epoch 44/200:\n",
            "Train Loss: 0.1394, Train Accuracy: 0.9523\n",
            "Val Loss: 0.0874, Val Accuracy: 0.9701, Val ROC AUC: 0.9968\n",
            "⚠️ No improvement in Val ROC AUC for 4 epoch(s). Best is 0.9970.\n",
            "\n",
            "===== Epoch 45/200 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[SUMMARY] Epoch 45/200:\n",
            "Train Loss: 0.1534, Train Accuracy: 0.9478\n",
            "Val Loss: 0.1396, Val Accuracy: 0.9518, Val ROC AUC: 0.9925\n",
            "⚠️ No improvement in Val ROC AUC for 5 epoch(s). Best is 0.9970.\n",
            "\n",
            "===== Epoch 46/200 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[SUMMARY] Epoch 46/200:\n",
            "Train Loss: 0.1505, Train Accuracy: 0.9481\n",
            "Val Loss: 0.1128, Val Accuracy: 0.9617, Val ROC AUC: 0.9945\n",
            "⚠️ No improvement in Val ROC AUC for 6 epoch(s). Best is 0.9970.\n",
            "\n",
            "===== Epoch 47/200 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[SUMMARY] Epoch 47/200:\n",
            "Train Loss: 0.1494, Train Accuracy: 0.9485\n",
            "Val Loss: 0.1788, Val Accuracy: 0.9294, Val ROC AUC: 0.9901\n",
            "⚠️ No improvement in Val ROC AUC for 7 epoch(s). Best is 0.9970.\n",
            "\n",
            "===== Epoch 48/200 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[SUMMARY] Epoch 48/200:\n",
            "Train Loss: 0.1399, Train Accuracy: 0.9521\n",
            "Val Loss: 0.1041, Val Accuracy: 0.9647, Val ROC AUC: 0.9956\n",
            "⚠️ No improvement in Val ROC AUC for 8 epoch(s). Best is 0.9970.\n",
            "\n",
            "===== Epoch 49/200 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[SUMMARY] Epoch 49/200:\n",
            "Train Loss: 0.1363, Train Accuracy: 0.9537\n",
            "Val Loss: 0.1726, Val Accuracy: 0.9388, Val ROC AUC: 0.9912\n",
            "⚠️ No improvement in Val ROC AUC for 9 epoch(s). Best is 0.9970.\n",
            "\n",
            "===== Epoch 50/200 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[SUMMARY] Epoch 50/200:\n",
            "Train Loss: 0.1385, Train Accuracy: 0.9533\n",
            "Val Loss: 0.0885, Val Accuracy: 0.9710, Val ROC AUC: 0.9965\n",
            "⚠️ No improvement in Val ROC AUC for 10 epoch(s). Best is 0.9970.\n",
            "\n",
            "🛑 Early stopping triggered after 10 epochs without improvement.\n",
            "\n",
            "Training Complete!\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Args:\n",
        "        image_size (int): Size of the input image (e.g., 224).\n",
        "        patch_size (int): Size of each patch (e.g., 16).\n",
        "        in_channels (int): Number of input channels (e.g., 1 for your task).\n",
        "        num_classes (int): Number of output classes (e.g., 3 for your task).\n",
        "        embed_dim (int): The main embedding dimension (e.g., 768 for ViT-Base).\n",
        "        depth (int): Number of Transformer Encoder blocks (e.g., 12 for ViT-Base).\n",
        "        num_heads (int): Number of attention heads (e.g., 12 for ViT-Base).\n",
        "        mlp_ratio (float): Ratio to determine MLP hidden dimension (e.g., 4.0).\n",
        "        dropout (float): Dropout probability.\n",
        "\"\"\"\n",
        "from torch.optim.lr_scheduler import LambdaLR, CosineAnnealingLR, SequentialLR\n",
        "batch_size = 32\n",
        "learning_rate = 5e-4\n",
        "weight_decay = 0.05\n",
        "num_epochs = 200\n",
        "warmup_epochs = 10\n",
        "model = VisionTransformer(\n",
        "        image_size=64, patch_size=4, in_channels=1, num_classes=3,\n",
        "                 embed_dim=192, depth=6, num_heads=4, mlp_ratio=4.0, dropout=0.1\n",
        "    )\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "\n",
        "\n",
        "#scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=1e-6)\n",
        "def warmup_lambda(current_epoch):\n",
        "    if current_epoch < warmup_epochs:\n",
        "        return float(current_epoch) / float(max(1, warmup_epochs))\n",
        "    return 1.0\n",
        "warmup_scheduler = LambdaLR(optimizer, lr_lambda=warmup_lambda)\n",
        "main_scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs - warmup_epochs, eta_min=1e-6)\n",
        "scheduler = SequentialLR(optimizer, schedulers=[warmup_scheduler, main_scheduler], milestones=[warmup_epochs])\n",
        "\n",
        "\n",
        "print(\"Optimizer: Adam\")\n",
        "print(f\"Learning Rate: {learning_rate}\")\n",
        "\n",
        "# Train Model\n",
        "model, all_probs, all_labels = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_-lEQtu_txF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "380b9897-dd4d-40ef-ba22-02663ddea4b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating ROC Curve\n",
            "Class 0 ROC AUC: 0.9985\n",
            "Class 1 ROC AUC: 0.9936\n",
            "Class 2 ROC AUC: 0.9974\n",
            "ROC Curve saved as roc_curve.png\n",
            "Training and Evaluation Complete!\n"
          ]
        }
      ],
      "source": [
        "\"\"\" ROC Curve Plotting Function\"\"\"\n",
        "def plot_roc_curve(all_preds, all_labels):\n",
        "    print(\"Generating ROC Curve\")\n",
        "\n",
        "    # Convert predictions and labels to numpy arrays\n",
        "    all_preds = np.array(all_preds)\n",
        "    all_labels = np.array(all_labels)\n",
        "\n",
        "    fpr = dict()\n",
        "    tpr = dict()\n",
        "    roc_auc = dict()\n",
        "    n_classes = 3\n",
        "\n",
        "    for i in range(n_classes):\n",
        "        fpr[i], tpr[i], _ = roc_curve((all_labels == i).astype(int), all_preds[:, i])\n",
        "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "        print(f\"Class {i} ROC AUC: {roc_auc[i]:.4f}\")\n",
        "\n",
        "    # Plot ROC curves\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    colors = ['blue', 'red', 'green']\n",
        "    class_names = ['Axion', 'CDM', 'No Substructure']\n",
        "\n",
        "    for i, color in zip(range(n_classes), colors):\n",
        "        plt.plot(fpr[i], tpr[i], color=color,\n",
        "                 label=f'{class_names[i]} (AUC = {roc_auc[i]:.2f})')\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.savefig('/content/drive/MyDrive/Model_III_dataset/roc_curve.png')\n",
        "    plt.close()\n",
        "\n",
        "    print(\"ROC Curve saved as roc_curve.png\")\n",
        "\n",
        "\n",
        "plot_roc_curve(all_probs, all_labels)\n",
        "\n",
        "print(\"Training and Evaluation Complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZ59pFZa_txG"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}