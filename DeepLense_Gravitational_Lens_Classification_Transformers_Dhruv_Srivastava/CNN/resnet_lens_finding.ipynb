{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBCm_vXmn4So",
        "outputId": "5b82bc99-1759-4da1-c7ba-d56015477c50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRM2kxST8KJZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "\"\"\"\n",
        "GSoC 2025 Internship Application Task - 1\n",
        "Author: Dhruv Srivastava\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"Import dependencies\"\"\"\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.models import resnet18\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vlKhVPANnVh1"
      },
      "outputs": [],
      "source": [
        "\"\"\"Define Dataset Class\"\"\"\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, data_dir, transform=None):\n",
        "\n",
        "        self.data = []\n",
        "        self.labels = []\n",
        "        self.class_names = ['axion', 'cdm', 'no_sub']\n",
        "\n",
        "        print(f\"Loading dataset from: {data_dir}\")\n",
        "        print(f\"Looking for classes: {self.class_names}\")\n",
        "\n",
        "        for idx, class_name in enumerate(self.class_names):\n",
        "            class_dir = os.path.join(data_dir, class_name)\n",
        "            print(f\"Processing class: {class_name} (index: {idx})\")\n",
        "\n",
        "            # Check if directory exists\n",
        "            if not os.path.exists(class_dir):\n",
        "                print(f\"[ERROR] Directory not found: {class_dir}\")\n",
        "                continue\n",
        "\n",
        "            files = os.listdir(class_dir)\n",
        "            print(f\"Found {len(files)} files in {class_name} directory\")\n",
        "\n",
        "            for file_name in files:\n",
        "                if file_name.endswith('.npy'):\n",
        "                    file_path = os.path.join(class_dir, file_name)\n",
        "\n",
        "                    # Load the numpy file\n",
        "                    loaded_data = np.load(file_path, allow_pickle=True)\n",
        "\n",
        "                    # Handle different data structures based on class name\n",
        "                    if class_name == 'axion':\n",
        "                        image = loaded_data[0]\n",
        "                        # Debug image loading for axion\n",
        "                        print(f\"Loading image: {file_name}\")\n",
        "                        print(f\"Original loaded shape for axion: {loaded_data.shape}, Extracted image shape: {image.shape}\")\n",
        "                    else: # For 'cdm' and 'no_sub'\n",
        "                        image = loaded_data\n",
        "                        # Debug image loading for cdm/no_sub\n",
        "                        print(f\"Loading image: {file_name}\")\n",
        "                        print(f\"Image shape for {class_name}: {image.shape}\")\n",
        "\n",
        "                    # Ensure all images are 3-channel (RGB-like)\n",
        "                    if len(image.shape) == 2:\n",
        "                        image = np.stack([image]*3, axis=0)\n",
        "                        print(\"Converted 2D image to 3-channel\")\n",
        "                    elif len(image.shape) == 3 and image.shape[0] == 1:\n",
        "                        image = np.repeat(image, 3, axis=0)\n",
        "                        print(\"Converted single-channel image to 3-channel\")\n",
        "\n",
        "                    self.data.append(torch.tensor(image, dtype=torch.float32))\n",
        "                    self.labels.append(idx)\n",
        "\n",
        "        print(f\"Total images loaded: {len(self.data)}\")\n",
        "        print(f\"Distribution of classes: {np.unique(self.labels, return_counts=True)}\")\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.data[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Define Dataset Class for Vision Transformer with Debugging\"\"\"\n",
        "class MyDatasetViT(Dataset):\n",
        "    def __init__(self, data_dir, transform=None):\n",
        "        self.data = []\n",
        "        self.labels = []\n",
        "        self.class_names = ['axion', 'cdm', 'no_sub']\n",
        "        self.transform = transform\n",
        "\n",
        "        print(f\"Loading dataset from: {data_dir}\")\n",
        "        print(f\"Looking for classes: {self.class_names}\")\n",
        "\n",
        "        for idx, class_name in enumerate(self.class_names):\n",
        "            class_dir = os.path.join(data_dir, class_name)\n",
        "            print(f\"--- Processing class: {class_name} ---\")\n",
        "\n",
        "            if not os.path.exists(class_dir):\n",
        "                print(f\"[ERROR] Directory not found: {class_dir}\")\n",
        "                continue\n",
        "\n",
        "            files = os.listdir(class_dir)\n",
        "\n",
        "            for file_name in files:\n",
        "                if file_name.endswith('.npy'):\n",
        "                    file_path = os.path.join(class_dir, file_name)\n",
        "                    loaded_data = np.load(file_path, allow_pickle=True)\n",
        "\n",
        "                    if class_name == 'axion':\n",
        "                        image = loaded_data[0]\n",
        "                    else:\n",
        "                        image = loaded_data\n",
        "\n",
        "                    # [DEBUG] Print the shape of the raw numpy array\n",
        "                    print(f\"  [DEBUG] Loaded '{file_name}'. Raw numpy shape: {image.shape}\")\n",
        "\n",
        "                    # Ensure the image is a 2D array (H, W) before adding channel dimension.\n",
        "                    if image.ndim != 2:\n",
        "                        image = np.squeeze(image)\n",
        "\n",
        "                    # Convert to a float tensor and add a channel dimension -> [1, H, W]\n",
        "                    image_tensor = torch.tensor(image, dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "                    # [DEBUG] Print the shape of the final tensor being stored in the dataset\n",
        "                    print(f\"  [DEBUG] Storing tensor with final shape: {image_tensor.shape}\\n\")\n",
        "\n",
        "                    self.data.append(image_tensor)\n",
        "                    self.labels.append(idx)\n",
        "\n",
        "        print(\"\\n--- Dataset Loading Complete ---\")\n",
        "        print(f\"Total images loaded: {len(self.data)}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        This method is called by the DataLoader to get one item from the dataset.\n",
        "        The debug prints here are CRITICAL for finding the error.\n",
        "        \"\"\"\n",
        "        #print(f\"--- Getting item index: {idx} ---\")\n",
        "\n",
        "        # Retrieve the pre-loaded tensor and its label\n",
        "        image = self.data[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # [DEBUG] Print shape BEFORE the transform is applied\n",
        "        #print(f\"  [DEBUG] Shape of tensor BEFORE transform: {image.shape}\")\n",
        "\n",
        "        # Apply transformations (e.g., resizing) if they are provided\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "            # [DEBUG] Print shape AFTER the transform is applied\n",
        "            #print(f\"  [DEBUG] Shape of tensor AFTER transform: {image.shape}\")\n",
        "        else:\n",
        "            #print(\"  [DEBUG] No transform was applied.\")\n",
        "            pass\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "tyvVkIA-q_BQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DYWEWf7nVh2",
        "outputId": "dedcf44d-cbd8-4752-dc43-2636093ba10b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Directory: /content/drive/MyDrive/Model_III_dataset/Model_III\n",
            "Batch Size: 32\n",
            "Number of Training Batches: 2096\n",
            "Number of Validation Batches: 420\n"
          ]
        }
      ],
      "source": [
        "# Hyperparameters\n",
        "batch_size = 32\n",
        "learning_rate = 0.001\n",
        "num_epochs = 500\n",
        "\n",
        "# Data Directories\n",
        "train_dir = '/content/drive/MyDrive/Model_III_dataset/Model_III'\n",
        "#val_dir = '../dataset/dataset/val'\n",
        "\n",
        "print(f\"Training Directory: {train_dir}\")\n",
        "#print(f\"Validation Directory: {val_dir}\")\n",
        "\n",
        "# Create Datasets and Dataloaders\n",
        "#train_dataset = MyDataset(train_dir)\n",
        "#val_dataset = MyDataset(val_dir)\n",
        "#dataset = MyDataset(train_dir)\n",
        "#train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [0.85, 0.15, 0.0])\n",
        "\n",
        "#import data loaders from file\n",
        "train_loader = torch.load('/content/drive/MyDrive/train_loader.pth', weights_only=False)\n",
        "val_loader = torch.load('/content/drive/MyDrive/val_loader.pth', weights_only=False)\n",
        "\n",
        "print(f\"Batch Size: {batch_size}\")\n",
        "print(f\"Number of Training Batches: {len(train_loader)}\")\n",
        "print(f\"Number of Validation Batches: {len(val_loader)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCts3sq4nVh3"
      },
      "outputs": [],
      "source": [
        "# Modified ResNet18 for Lens Classification\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes=3):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        print(\"Initializing Modified ResNet18\")\n",
        "\n",
        "        # Load ResNet18\n",
        "        resnet = resnet18(pretrained=True)\n",
        "\n",
        "        # Modify first conv layer to accept single-channel input\n",
        "        resnet.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "\n",
        "        # Replace the last layer\n",
        "        num_features = resnet.fc.in_features\n",
        "        resnet.fc = nn.Sequential(\n",
        "            nn.Linear(num_features, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "        self.model = resnet\n",
        "\n",
        "        print(f\"Model architecture: {self.model}\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLQQ7Hc-nVh4"
      },
      "outputs": [],
      "source": [
        "\"\"\"Training and Evaluation\"\"\"\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=50):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Training on device: {device}\")\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    best_val_accuracy = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\\n===== Epoch {epoch+1}/{num_epochs} =====\")\n",
        "\n",
        "        # Training Phase\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        train_correct = 0\n",
        "\n",
        "        for batch_idx, (images, labels) in enumerate(train_loader):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # Debug information\n",
        "            #print(f\"Training Batch {batch_idx+1}/{len(train_loader)}\")\n",
        "            #print(f\"Batch images shape: {images.shape}\")\n",
        "            #print(f\"Batch labels: {labels}\")\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "\n",
        "            batch_accuracy = (predicted == labels).float().mean().item()\n",
        "            #print(f\"Batch Loss: {loss.item():.4f}, Batch Accuracy: {batch_accuracy:.4f}\")\n",
        "\n",
        "        # Validation Phase\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_correct = 0\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (images, labels) in enumerate(val_loader):\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "                # Debug validation information\n",
        "                #print(f\"Validation Batch {batch_idx+1}/{len(val_loader)}\")\n",
        "                #print(f\"Batch images shape: {images.shape}\")\n",
        "                #print(f\"Batch labels: {labels}\")\n",
        "\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                val_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "\n",
        "                probs = torch.softmax(outputs, dim=1)\n",
        "                all_preds.extend(probs.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "\n",
        "                batch_accuracy = (predicted == labels).float().mean().item()\n",
        "               #print(f\"Validation Batch Loss: {loss.item():.4f}, Validation Batch Accuracy: {batch_accuracy:.4f}\")\n",
        "\n",
        "\n",
        "        train_accuracy = train_correct / len(train_loader.dataset)\n",
        "        val_accuracy = val_correct / len(val_loader.dataset)\n",
        "\n",
        "        # Epoch-level metrics\n",
        "        print(f'\\n[SUMMARY] Epoch {epoch+1}/{num_epochs}:')\n",
        "        print(f'Train Loss: {train_loss/len(train_loader):.4f}, Train Accuracy: {train_accuracy:.4f}')\n",
        "        print(f'Val Loss: {val_loss/len(val_loader):.4f}, Val Accuracy: {val_accuracy:.4f}')\n",
        "\n",
        "        # Save best model\n",
        "        if val_accuracy > best_val_accuracy:\n",
        "            best_val_accuracy = val_accuracy\n",
        "            torch.save(model.state_dict(), '/content/drive/MyDrive/lens_classifier_model.pth')\n",
        "            print(f\"New best model saved with validation accuracy: {best_val_accuracy:.4f}\")\n",
        "\n",
        "    print(\"\\nTraining Complete!\")\n",
        "    return all_preds, all_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsPzUUkxnVh5",
        "outputId": "5943a0c5-d8b8-49d5-fc02-7cc27eb3e9fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing Modified ResNet18\n",
            "Model architecture: ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=512, out_features=3, bias=True)\n",
            "  )\n",
            ")\n",
            "Optimizer: Adam\n",
            "Learning Rate: 0.001\n",
            "Training on device: cuda\n",
            "\n",
            "===== Epoch 1/27 =====\n",
            "\n",
            "[SUMMARY] Epoch 1/27:\n",
            "Train Loss: 0.4997, Train Accuracy: 0.7800\n",
            "Val Loss: 0.4173, Val Accuracy: 0.8294\n",
            "New best model saved with validation accuracy: 0.8294\n",
            "\n",
            "===== Epoch 2/27 =====\n",
            "\n",
            "[SUMMARY] Epoch 2/27:\n",
            "Train Loss: 0.2459, Train Accuracy: 0.9015\n",
            "Val Loss: 2.2725, Val Accuracy: 0.6816\n",
            "\n",
            "===== Epoch 3/27 =====\n",
            "\n",
            "[SUMMARY] Epoch 3/27:\n",
            "Train Loss: 0.1676, Train Accuracy: 0.9359\n",
            "Val Loss: 0.6957, Val Accuracy: 0.7419\n",
            "\n",
            "===== Epoch 4/27 =====\n",
            "\n",
            "[SUMMARY] Epoch 4/27:\n",
            "Train Loss: 0.1318, Train Accuracy: 0.9510\n",
            "Val Loss: 0.0840, Val Accuracy: 0.9665\n",
            "New best model saved with validation accuracy: 0.9665\n",
            "\n",
            "===== Epoch 5/27 =====\n",
            "\n",
            "[SUMMARY] Epoch 5/27:\n",
            "Train Loss: 0.1018, Train Accuracy: 0.9620\n",
            "Val Loss: 0.0406, Val Accuracy: 0.9844\n",
            "New best model saved with validation accuracy: 0.9844\n",
            "\n",
            "===== Epoch 6/27 =====\n",
            "\n",
            "[SUMMARY] Epoch 6/27:\n",
            "Train Loss: 0.0797, Train Accuracy: 0.9714\n",
            "Val Loss: 0.0333, Val Accuracy: 0.9899\n",
            "New best model saved with validation accuracy: 0.9899\n",
            "\n",
            "===== Epoch 7/27 =====\n",
            "\n",
            "[SUMMARY] Epoch 7/27:\n",
            "Train Loss: 0.0740, Train Accuracy: 0.9764\n",
            "Val Loss: 3.4325, Val Accuracy: 0.5766\n",
            "\n",
            "===== Epoch 8/27 =====\n",
            "\n",
            "[SUMMARY] Epoch 8/27:\n",
            "Train Loss: 0.0558, Train Accuracy: 0.9804\n",
            "Val Loss: 0.2486, Val Accuracy: 0.9095\n",
            "\n",
            "===== Epoch 9/27 =====\n",
            "\n",
            "[SUMMARY] Epoch 9/27:\n",
            "Train Loss: 0.0519, Train Accuracy: 0.9834\n",
            "Val Loss: 4.9877, Val Accuracy: 0.6427\n",
            "\n",
            "===== Epoch 10/27 =====\n",
            "\n",
            "[SUMMARY] Epoch 10/27:\n",
            "Train Loss: 0.0541, Train Accuracy: 0.9821\n",
            "Val Loss: 6.1510, Val Accuracy: 0.5719\n",
            "\n",
            "===== Epoch 11/27 =====\n",
            "\n",
            "[SUMMARY] Epoch 11/27:\n",
            "Train Loss: 0.0410, Train Accuracy: 0.9867\n",
            "Val Loss: 0.8129, Val Accuracy: 0.9025\n",
            "\n",
            "===== Epoch 12/27 =====\n",
            "\n",
            "[SUMMARY] Epoch 12/27:\n",
            "Train Loss: 0.0405, Train Accuracy: 0.9868\n",
            "Val Loss: 0.1557, Val Accuracy: 0.9176\n",
            "\n",
            "===== Epoch 13/27 =====\n",
            "\n",
            "[SUMMARY] Epoch 13/27:\n",
            "Train Loss: 0.0387, Train Accuracy: 0.9872\n",
            "Val Loss: 4.2738, Val Accuracy: 0.5882\n",
            "\n",
            "===== Epoch 14/27 =====\n",
            "\n",
            "[SUMMARY] Epoch 14/27:\n",
            "Train Loss: 0.0794, Train Accuracy: 0.9816\n",
            "Val Loss: 1.4439, Val Accuracy: 0.6855\n",
            "\n",
            "===== Epoch 15/27 =====\n",
            "\n",
            "[SUMMARY] Epoch 15/27:\n",
            "Train Loss: 0.0340, Train Accuracy: 0.9889\n",
            "Val Loss: 0.1637, Val Accuracy: 0.9248\n",
            "\n",
            "===== Epoch 16/27 =====\n",
            "\n",
            "[SUMMARY] Epoch 16/27:\n",
            "Train Loss: 0.0310, Train Accuracy: 0.9901\n",
            "Val Loss: 0.0240, Val Accuracy: 0.9955\n",
            "New best model saved with validation accuracy: 0.9955\n",
            "\n",
            "===== Epoch 17/27 =====\n",
            "\n",
            "[SUMMARY] Epoch 17/27:\n",
            "Train Loss: 0.0279, Train Accuracy: 0.9909\n",
            "Val Loss: 1.0265, Val Accuracy: 0.6917\n",
            "\n",
            "===== Epoch 18/27 =====\n",
            "\n",
            "[SUMMARY] Epoch 18/27:\n",
            "Train Loss: 0.0307, Train Accuracy: 0.9902\n",
            "Val Loss: 6.4262, Val Accuracy: 0.5368\n",
            "\n",
            "===== Epoch 19/27 =====\n",
            "\n",
            "[SUMMARY] Epoch 19/27:\n",
            "Train Loss: 0.0270, Train Accuracy: 0.9911\n",
            "Val Loss: 8.6779, Val Accuracy: 0.5304\n",
            "\n",
            "===== Epoch 20/27 =====\n",
            "\n",
            "[SUMMARY] Epoch 20/27:\n",
            "Train Loss: 0.0305, Train Accuracy: 0.9901\n",
            "Val Loss: 0.0841, Val Accuracy: 0.9772\n",
            "\n",
            "===== Epoch 21/27 =====\n",
            "\n",
            "[SUMMARY] Epoch 21/27:\n",
            "Train Loss: 0.0257, Train Accuracy: 0.9919\n",
            "Val Loss: 10.5783, Val Accuracy: 0.7227\n",
            "\n",
            "===== Epoch 22/27 =====\n",
            "\n",
            "[SUMMARY] Epoch 22/27:\n",
            "Train Loss: 0.0268, Train Accuracy: 0.9915\n",
            "Val Loss: 0.2660, Val Accuracy: 0.9388\n",
            "\n",
            "===== Epoch 23/27 =====\n",
            "\n",
            "[SUMMARY] Epoch 23/27:\n",
            "Train Loss: 0.0258, Train Accuracy: 0.9922\n",
            "Val Loss: 0.1403, Val Accuracy: 0.9391\n",
            "\n",
            "===== Epoch 24/27 =====\n",
            "\n",
            "[SUMMARY] Epoch 24/27:\n",
            "Train Loss: 0.0252, Train Accuracy: 0.9918\n",
            "Val Loss: 0.1966, Val Accuracy: 0.9077\n",
            "\n",
            "===== Epoch 25/27 =====\n",
            "\n",
            "[SUMMARY] Epoch 25/27:\n",
            "Train Loss: 0.0239, Train Accuracy: 0.9928\n",
            "Val Loss: 0.8287, Val Accuracy: 0.7514\n",
            "\n",
            "===== Epoch 26/27 =====\n",
            "\n",
            "[SUMMARY] Epoch 26/27:\n",
            "Train Loss: 0.0341, Train Accuracy: 0.9889\n",
            "Val Loss: 0.7037, Val Accuracy: 0.8114\n",
            "\n",
            "===== Epoch 27/27 =====\n",
            "\n",
            "[SUMMARY] Epoch 27/27:\n",
            "Train Loss: 0.0213, Train Accuracy: 0.9932\n",
            "Val Loss: 0.0231, Val Accuracy: 0.9974\n",
            "New best model saved with validation accuracy: 0.9974\n",
            "\n",
            "Training Complete!\n"
          ]
        }
      ],
      "source": [
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "# Initialize Model\n",
        "model = Net(num_classes=3)\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=1e-6)\n",
        "\n",
        "print(\"Optimizer: Adam\")\n",
        "print(f\"Learning Rate: {learning_rate}\")\n",
        "\n",
        "\n",
        "# Train Model\n",
        "all_preds, all_labels = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, 27)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZjZ2Bp9nVh5",
        "outputId": "eb5fe555-057d-46e9-ff9c-3dd243d6ce43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating ROC Curve\n",
            "Initializing Modified ResNet18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model architecture: ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=512, out_features=3, bias=True)\n",
            "  )\n",
            ")\n",
            "Class 0 ROC AUC: 0.9999\n",
            "Class 1 ROC AUC: 0.9999\n",
            "Class 2 ROC AUC: 1.0000\n",
            "ROC Curve saved as roc_curve.png\n",
            "Training and Evaluation Complete!\n"
          ]
        }
      ],
      "source": [
        "\"\"\" ROC Curve Plotting Function\"\"\"\n",
        "def plot_roc_curve(all_preds, all_labels):\n",
        "    print(\"Generating ROC Curve\")\n",
        "\n",
        "    #Load model from file\n",
        "    model = Net(num_classes=3)\n",
        "    model.load_state_dict(torch.load('/content/drive/MyDrive/lens_classifier_model.pth'))\n",
        "\n",
        "    # Convert predictions and labels to numpy arrays\n",
        "    all_preds = np.array(all_preds)\n",
        "    all_labels = np.array(all_labels)\n",
        "\n",
        "    fpr = dict()\n",
        "    tpr = dict()\n",
        "    roc_auc = dict()\n",
        "    n_classes = 3\n",
        "\n",
        "    for i in range(n_classes):\n",
        "        fpr[i], tpr[i], _ = roc_curve((all_labels == i).astype(int), all_preds[:, i])\n",
        "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "        print(f\"Class {i} ROC AUC: {roc_auc[i]:.4f}\")\n",
        "\n",
        "    # Plot ROC curves\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    colors = ['blue', 'red', 'green']\n",
        "    class_names = ['No Substructure', 'Sphere Substructure', 'Vortex Substructure']\n",
        "\n",
        "    for i, color in zip(range(n_classes), colors):\n",
        "        plt.plot(fpr[i], tpr[i], color=color,\n",
        "                 label=f'{class_names[i]} (AUC = {roc_auc[i]:.2f})')\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.savefig('/content/drive/MyDrive/roc_curve.png')\n",
        "    plt.close()\n",
        "\n",
        "    print(\"ROC Curve saved as roc_curve.png\")\n",
        "\n",
        "\n",
        "plot_roc_curve(all_preds, all_labels)\n",
        "\n",
        "print(\"Training and Evaluation Complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecuCEuiInVh6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}