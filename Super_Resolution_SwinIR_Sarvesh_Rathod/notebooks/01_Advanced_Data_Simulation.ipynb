{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 01. Advanced Data Simulation for Gravitational Lensing Super-Resolution\n",
        "\n",
        "**Objective**: Generate high-fidelity simulated gravitational lensing images to train the SwinIR model. \n",
        "\n",
        "This notebook covers:\n",
        "1. **SIE Lens Modeling**: Simulating Singular Isothermal Ellipsoid mass distributions.\n",
        "2. **Real Galaxy Sources**: Using `Galaxy10_DECals` images as the source light to achieve realistic morphological variety.\n",
        "3. **Multi-Resolution Simulation**: Creating paired High-Resolution (HR) and Low-Resolution (LR) images based on Euclid mission specifications.\n",
        "4. **Data Preprocessing**: Normalization, filtering, and dataset preparation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Setup and Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import copy\n",
        "import numpy as np\n",
        "import h5py\n",
        "import random\n",
        "import os\n",
        "import cv2\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "from lenstronomy.SimulationAPI.sim_api import SimAPI\n",
        "from lenstronomy.SimulationAPI.ObservationConfig.Euclid import Euclid\n",
        "from astropy.cosmology import FlatLambdaCDM\n",
        "\n",
        "# Configuration\n",
        "OUTPUT_DIR = \"../pairs\"\n",
        "DATA_FILE = r\"../../DeepLenseSim/data/Galaxy10_DECals.h5\"\n",
        "PROCESSED_DATA_DIR = \"../data_diff\"\n",
        "NUM_SIMS = 2500\n",
        "SEED = 42\n",
        "\n",
        "np.random.seed(SEED)\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "os.makedirs(PROCESSED_DATA_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"Target Output Directory: {OUTPUT_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Simulation Physics Engine\n",
        "We use `lenstronomy` to simulate the gravitational lensing effect. We define a standard Euclid-like instrument configuration and adjust the pixel scale for super-resolution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cosmo = FlatLambdaCDM(H0=70, Om0=0.3, Ob0=0.)\n",
        "Euclid_g = Euclid(band='VIS', psf_type='GAUSSIAN', coadd_years=6)\n",
        "kwargs_g_band = Euclid_g.kwargs_single_band()\n",
        "\n",
        "def get_simulation_api(numpix, kwargs_band):\n",
        "    kwargs_model = {'lens_model_list': ['SIE'], \n",
        "                    'lens_redshift_list': [0.5], \n",
        "                    'lens_light_model_list': ['SERSIC_ELLIPSE', 'SERSIC_ELLIPSE'], \n",
        "                    'source_light_model_list': ['INTERPOL'], \n",
        "                    'source_redshift_list': [1.0], \n",
        "                    'cosmo': cosmo, \n",
        "                    'z_source_convention': 2.5, \n",
        "                    'z_source': 2.5}\n",
        "    return SimAPI(numpix=numpix, kwargs_single_band=kwargs_band, kwargs_model=kwargs_model)\n",
        "\n",
        "def simulate_pair(image_galaxy, sigma_v, source_pos_xx, source_pos_yy, source_ang, idx):\n",
        "    # HR Config (Upscale Factor x2)\n",
        "    kwargs_g_hr = copy.deepcopy(kwargs_g_band)\n",
        "    kwargs_g_hr['pixel_scale'] = 0.05 \n",
        "    sim_hr = get_simulation_api(128, kwargs_g_hr)\n",
        "    imSim_hr = sim_hr.image_model_class({'point_source_supersampling_factor': 1})\n",
        "    \n",
        "    # LR Config (Base Resolution)\n",
        "    kwargs_g_lr = copy.deepcopy(kwargs_g_band)\n",
        "    kwargs_g_lr['pixel_scale'] = 0.1 \n",
        "    sim_lr = get_simulation_api(64, kwargs_g_lr)\n",
        "    imSim_lr = sim_lr.image_model_class({'point_source_supersampling_factor': 1})\n",
        "    \n",
        "    # Lens Mass\n",
        "    kwargs_mass = [{'sigma_v': sigma_v, 'center_x': 0, 'center_y': 0, 'e1': 0.0, 'e2': 0}]\n",
        "    \n",
        "    # Process Source Light (Real Galaxy)\n",
        "    image_data = image_galaxy[:,:,0].astype(float)\n",
        "    image_data -= np.median(image_data[:50, :50])\n",
        "    \n",
        "    kwargs_source_mag = [{'magnitude': 22, 'image': image_data, 'scale': 0.0025, 'phi_G': source_ang, 'center_x': source_pos_xx, 'center_y': source_pos_yy}]\n",
        "    \n",
        "    # Lens Light (Elliptical Sersic Profiles)\n",
        "    kwargs_lens_light_mag = [{'magnitude': 17, 'R_sersic': 0.4, 'n_sersic': 2.3, 'e1': 0, 'e2': 0.05, 'center_x': 0, 'center_y': 0},\n",
        "                             {'magnitude': 28, 'R_sersic': 1.5, 'n_sersic': 1.2, 'e1': 0, 'e2': 0.3, 'center_x': 0, 'center_y': 0}]\n",
        "\n",
        "    kwargs_lens_light_hr, kwargs_source_hr, _ = sim_hr.magnitude2amplitude(kwargs_lens_light_mag, kwargs_source_mag)\n",
        "    kwargs_lens_light_lr, kwargs_source_lr, _ = sim_lr.magnitude2amplitude(kwargs_lens_light_mag, kwargs_source_mag)\n",
        "    kwargs_lens = sim_hr.physical2lensing_conversion(kwargs_mass=kwargs_mass)\n",
        "\n",
        "    # Generate Images\n",
        "    image_hr = imSim_hr.image(kwargs_lens, kwargs_source_hr, kwargs_lens_light_hr)\n",
        "    image_lr = imSim_lr.image(kwargs_lens, kwargs_source_lr, kwargs_lens_light_lr)\n",
        "\n",
        "    # Add Instrument Noise\n",
        "    image_hr += sim_hr.noise_for_model(model=image_hr) * 0.5 \n",
        "    image_lr += sim_lr.noise_for_model(model=image_lr)\n",
        "\n",
        "    return image_hr, image_lr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Load Real Galaxies\n",
        "We load unbarred spiral galaxies from the `Galaxy10_DECals` dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not os.path.exists(DATA_FILE):\n",
        "    raise FileNotFoundError(f\"Galaxy10 data not found at {DATA_FILE}\")\n",
        "\n",
        "with h5py.File(DATA_FILE, 'r') as F:\n",
        "    images = np.array(F['images'])\n",
        "    labels = np.array(F['ans'])\n",
        "    redshift = np.array(F['redshift'])\n",
        "\n",
        "# Filter for specific morphology if needed (Class 6: Unbarred Spiral)\n",
        "spiral_indices = np.where((labels == 6) & (redshift < 0.02))[0]\n",
        "print(f\"Found {len(spiral_indices)} suitable galaxies.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. Run Simulation Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"Simulating {NUM_SIMS} pairs...\")\n",
        "for i in tqdm(range(NUM_SIMS)):\n",
        "    gal_idx = spiral_indices[np.random.randint(0, len(spiral_indices))]\n",
        "    \n",
        "    # Stochastic Lensing Parameters\n",
        "    sigma_v = np.random.normal(260, 20)\n",
        "    source_pos_x = np.random.uniform(-0.3, 0.3)\n",
        "    source_pos_y = np.random.uniform(-0.3, 0.3)\n",
        "    source_ang = np.random.uniform(-np.pi, np.pi)\n",
        "    \n",
        "    hr, lr = simulate_pair(images[gal_idx], sigma_v, source_pos_x, source_pos_y, source_ang, i)\n",
        "    \n",
        "    np.save(os.path.join(OUTPUT_DIR, f'{i}_lensing_hsc.npy'), hr)\n",
        "    np.save(os.path.join(OUTPUT_DIR, f'{i}_lensing_hst.npy'), lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5. Post-Processing & Dataset Aggregation\n",
        "This section consolidates the individual `.npy` files into single training tensors and performs normalization ($[-1, 1]$ range)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_and_save():\n",
        "    files = [f for f in os.listdir(OUTPUT_DIR) if f.endswith(\".npy\")]\n",
        "    HR_list, LR_list = [], []\n",
        "    indices = sorted(list(set([int(f.split('_')[0]) for f in files])))\n",
        "    \n",
        "    for idx in tqdm(indices, desc=\"Processing\"):\n",
        "        hr_path = os.path.join(OUTPUT_DIR, f\"{idx}_lensing_hsc.npy\")\n",
        "        lr_path = os.path.join(OUTPUT_DIR, f\"{idx}_lensing_hst.npy\")\n",
        "        \n",
        "        # Load and Normalize\n",
        "        hr = np.load(hr_path)\n",
        "        lr = np.load(lr_path)\n",
        "        \n",
        "        # Min-Max Scaling -> [-1, 1]\n",
        "        hr = (hr - np.min(hr)) / (np.max(hr) - np.min(hr) + 1e-7)\n",
        "        lr = (lr - np.min(lr)) / (np.max(lr) - np.min(lr) + 1e-7)\n",
        "        \n",
        "        # Resizing to exact targets (Standardizing)\n",
        "        hr = cv2.resize(hr, (128, 128), interpolation=cv2.INTER_CUBIC)\n",
        "        lr = cv2.resize(lr, (64, 64), interpolation=cv2.INTER_CUBIC)\n",
        "        \n",
        "        hr = 2 * hr - 1\n",
        "        lr = 2 * lr - 1\n",
        "        \n",
        "        HR_list.append(hr[np.newaxis, ...])\n",
        "        LR_list.append(lr[np.newaxis, ...])\n",
        "        \n",
        "    HR = np.array(HR_list)\n",
        "    LR = np.array(LR_list)\n",
        "    \n",
        "    # Split 90/10 for train/test\n",
        "    split_idx = int(0.9 * len(HR))\n",
        "    \n",
        "    np.save(os.path.join(PROCESSED_DATA_DIR, 'train_HR.npy'), HR[:split_idx])\n",
        "    np.save(os.path.join(PROCESSED_DATA_DIR, 'train_LR.npy'), LR[:split_idx])\n",
        "    np.save(os.path.join(PROCESSED_DATA_DIR, 'test_HR.npy'), HR[split_idx:])\n",
        "    np.save(os.path.join(PROCESSED_DATA_DIR, 'test_LR.npy'), LR[split_idx:])\n",
        "    \n",
        "    print(f\"Saved processed data to {PROCESSED_DATA_DIR}\")\n",
        "    print(f\"Train Shape: {HR[:split_idx].shape}\")\n",
        "    \n",
        "process_and_save()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6. Visualization\n",
        "Verify the resolution difference visually."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "HR = np.load(os.path.join(PROCESSED_DATA_DIR, 'train_HR.npy'))\n",
        "LR = np.load(os.path.join(PROCESSED_DATA_DIR, 'train_LR.npy'))\n",
        "\n",
        "idx = np.random.randint(0, len(HR))\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(LR[idx].squeeze(), cmap='inferno')\n",
        "plt.title(\"Low Resolution Input (64x64)\")\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(HR[idx].squeeze(), cmap='inferno')\n",
        "plt.title(\"High Resolution Ground Truth (128x128)\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}